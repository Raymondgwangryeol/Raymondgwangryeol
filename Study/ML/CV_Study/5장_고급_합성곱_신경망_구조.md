## 5장. 고급 합성곱 신경망 구조 
</br>
강의: 세종대학교 최유경교수님 딥러닝시스템 강의(2023)     
</br></br>

## 목차
1. CNN의 디자인 패턴
2. LeNet-5
3. AlexNet
4. VGGNet
5. 인셉션과 GoogLeNet
6. ResNet
</br></br></br>

## 5-1. CNN의 디자인 패턴
디자인 패턴이란, 딥러닝 모델 설계 시 사용하는 패턴 구조를 말함.   
</br>

#### 패턴1. 특징 추출과 분류
합성곱 신경망은 크게 특징 추출을 하는 부분과 분류를 맡는 부분으로 나뉨.   
특징 추출 부분은 일련의 합성곱층, 분류 부분은 전결합층으로 구성되며, 거의 모든 합성곱 신경망이 이 구조를 따름.    
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-1.png"></img></br>

#### 패턴2. 이미지 깊이 증가, 크기는 감소
모든 층은 높이, 폭, 깊이(색상 채널이라고도 함)를 가진 3차원의 이미지를 입력으로 받음. 이후 계층에서 깊이는 색상 채널 대신 이전 층에서 추출된 특징을 나타내는 특징맵이 됨.       
이전 층에서 생성된 새로운 이미지에 합성곱 연산이 적용되고, 합성곱층을 지날 때 마다 이미지의 깊이는 증가하고 크기는 감소하는 경향이 있음.    
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-2.png"></img></br>

#### 패턴3. 전결합층
대부분 모든 전결합층은 유닛수가 같거나, 이어지는 유닛 수가 감소하는 패턴을 보임(증가하는 경우는 거의 없음).   
이어지는 모든 전결합층의 유닛을 같게 했다고 신경망의 학습 능력이 낮아지는 건 아님.   
</br></br></br>

## 5-2. LeNet-5
가중치를 가진 5개의 층(합성곱층 3개, 전결합층 2개)로 구성된 직관적인 구조.    
LeNet으로 MNIST 데이터셋을 학습시 99%이상의 높은 정확도가 나옴.    
</br>

#### 구조(C는 합성곱층, S는 풀링층, FC는 전결합층)
입력 이미지 → **C1** → TANH → S2 → **C3** → TANH → S4 → **C5** → TANH → **FC6** → **SOFTMAX**

</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-3.png"></img></br>

- 각 합성층의 필터 수    
  C1: 6, C3: 16, C5: 120    
- 각 합성층의 커널 크기
  5 X 5   
- 풀링층(서브샘플링층)      
  2 X 2, 평균 풀링 사용     
LeNet-5이 나올 당시 ReLU 함수가 없을 때여서(1998년) 일반적으로 활성화 함수로 tanh함수랑 시그모이드가 사용됨. 시그모이드보다 tanh 함수가 가중치값을 더 빨리 수렴한다고 생각해서 tanh를 씀.       
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-4.png"></img></br>

- LeNet-5 학습률 감쇠
처음 2번은 0.005, 그 다음 3번은 0.0002, 그 다음 4번은 0.00005, 그 이후는 0.00001의 학습률이 적용     
논문의 실험에서는 20에포크까지 학습을 수행.     
</br>

#### +) 은닉층의 활성화 함수를 ReLU로 교체한다면?     
실습해보기     
</br></br></br>

## 5-3. AlexNet
가중치가 있는 8개의 층(합성곱층 5개, 전결합층 3개)으로 구성된 구조. 복잡도가 높은 이미지넷 문제 해결을 위해 제안된 신경망. MNIST 문제는 LeNet이 더 높은 성능을 보였으나, 복잡한 문제 해결은 AlexNet이 더 성능이 좋음.     
2012 ILSVRC에서 15.3%의 Top-5 오차율(상위 5개의 예측값 중에서 정답이 있는 확률)을 기록했고, 2위보다 아주 높은 정답률을 보임. 이후 컴퓨터 비전 분야에서 본격적으로 딥러닝을 도입, 합성곱 신경망의 응용이 확산되는 계기가 됨.    
</br>

합성곱층, 풀링층의 조합 이후 전결합층, 소프트맥스 활성화 함수로 이어지는 기본 구조는 LeNet과 비슷함. 하지만 층수가 훨씬 많고, 규모가 큼.(65만개 뉴런, 6천만개의 파라미터) 때문에 훨씬 복잡한 특징을 학습할 수 있었음.      
</br>

#### 구조     
입력이미지  → **Conv1** → Pool2  → **Conv3**  → Pool4  → **Conv5**  → **Conv6**  → **Conv7**  → Pool8  → **FC9**  → **FC10**  → **SOFTMAX7**

 </br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-6.png"></img></br>

- **합성곱층 필터 크기**    
  11 X 11, 5 X 5, 3 X 3     
- **최대 풀링 사용**      
- **과적합 방지 위해 드롭아웃 적용**     
  뉴런 간 상호 적응 방지, 다양한 조합의 뉴런에 도움을 주는 유용한 특징을 학습. 드롭아웃 비율은 0.5          
- **은닉층 활성화 함수는 ReLU, 출력층 활성화 함수는 소프트맥스**    
  ReLU 사용으로 학습시간 크게 단축, tanh나 시그모이드의 기울기 소실 문제 해결      
- **데이터 강화**    
- **국소 응답 정규화 적용(Local Response Nomalization)**     
  가중치가 빨리 수렴되도록 하는 것이 목적. 배치 정규화랑 다른 기법임. 현재는 배치 정규화가 많이 사용됨.     
- **0.00005의 가중치 감쇠**
- **가중치 규제화**(L2 규제화와 같은 개념)    
- **다중 GPU 사용**    
  당시 사용하던 GTX 580으로 이미지넷 문제를 학습하기에는 어려웠음. 그래서 신경망을 2개의 GPU에 나눠 담아 학습하는 복잡한 방식을 개발함. 오늘날에는 해당 기법이 매우 발전함.     
</br>

90 에포크를 학습하였고, 초기 학습률은 0.01, 모멘텀은 0.9로 설정함. 검증 오차가 개선되지 않을 경우 학습률을 이전 학습률의 1/10로 조정.     
</br></br></br>


## 5-4. VGGNet
여러 버전이 있으며, LeNet이나 AlexNet과 구성 요소는 동일하지만 신경망 층수가 더 많음. 모든 층의 하이퍼파라미터가 동일하게 설정된 것이 특징이며, 신경망을 이해하기 쉬움.      
VGG16과 VGG19의 이미지넷 문제 Top-5오차는 각각 8.1%, 7.4%를 기록함.   
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-8.png"></img></br>

- 가중치 감쇠율 5X10^(-4) 적용한 L2 규제화    
- 드롭아웃 비율 0.5, 마지막 층 제외 두 전결합층에 적용    
- 미니배치 경사 하강법, 모멘텀 0.9   
- 학습률 초기값 0.01, 검증 데이터 정확도 정체되면 1/10배 감소(AlexNet과 같음)      
</br>

3 X 3크기 커널을 여러 층 쌓은 합성곱층 사이에 간간이 2 X 2크기의 풀링층을 끼워놓는 식의 구성. 합성곱층은 3 X 3크기의 필터, 스트라이드 1, 패딩 1이 적용되었고, 모든 풀링층은 2 X 2크기의 풀링 영역과 스트라이드 2가 적용됨.    
앞에 나왔던 구조들과 다르게 합성곱층의 필터 크기를 3X3으로 줄였는데, 그 이유는 더 세밀한 특징을 추출하기 위함임.    
또한 수용영역의 크기가 같을 때 크기가 큰 커널 하나보다 작은 크기의 커널 여러개가 성능이 더 좋음. 이유는 커널을 여러개 쌓아서 비선형층을 늘리는 것 = 신경망의 층수를 늘리는 것이기 때문.           
</br>

- 커널 크기 3X3인 합성곱층 2개 = 5X5 수용영역 가진 합성곱층     
- 커널 크기 3X3인 합성곱층 3개 = 7X7 수용영역 가진 합성곱층     
</br>

파라미터 수를 억제하는 효과도 있어 낮은 비용으로 더 복잡한 특징 학습 가능.      
</br>

- C개 채널을 가진 7X7 크기 커널을 가진 단일 합성곱층 파라미터 수 = 7²XC² = 49C²   
- 3X3 크기의 커널 3개 쌓은 구조 파라미터 수 = 3*3²C² = 27C² → 절반 가까이 억제    
</br>

VGG16, VGG19가 층수가 더 많아서 더 복잡한 모델을 학습할 수 있어 구현에 자주 사용됨.  
VGG16이 VGG19보다 적은 파라미터로 거의 동등한 성능을 내기 때문에, 일반적으로 VGG16이 더 많이 쓰임.    
</br></br></br>

## 5-5. 인셉션과 GoogLeNet        
### ■ 인셉션 구조
GoogLeNet은 앞선 구조들과 달리, 고전 CNN구조를 따르되, 인셉션 모듈과 풀링층을 쌓는 구조임.(기존 방식은 합성곱층과 풀링층)        
인셉션 모듈을 사용하면서, 블록 전체에 동일한 합성곱 필터 크기나 풀링층 배치를 적용시킴. → 인셉션 모듈의 단순 표현(Native Representation)      

 </br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-11.png"></img></br>

#### 인셉션 모듈 구성    
1X1, 3X3, 5X5 합성곱층, 3X3 최대 풀링층으로 구성.   
각 층의 출력은 연접처리(Concatenation)을 통해 하나의 출력으로 이어 붙여져서 다음 단계 입력으로 넘어감.    
</br>

#### 차원 축소가 적용된 인셉션 모듈     

</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-12.png"></img></br>

**1X1 합성곱층? (1차원 축소층)**    
이미지의 크기는 그대로 두고, 차원(깊이, 또는 채널)를 줄여 연산을 줄임.     
#### 과격한 차원 축소는 신경망 성능에 나쁜 영향을 주진 않을까?     
적정 수준의 차원 축소는 성능에 영향을 미치지 않음.    
</br>

1차원 축소층이 적용된 인셉션 모듈은 다음과 같음.   
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-13.png"></img></br>    

- 3X3, 5X5 합성곱층 앞에 각각 1차원 축소층을 배치.      
- 풀링층은 어차피 차원 축소 등 가중치가 없기 때문에, 풀링층 앞에 놓지 않고 풀링층 뒤에 배치해서 해당 층 출력 값에 차원 축소를 적용.    
</br>

### ■ GoogLeNet 구조
GoogLeNet은 **인셉션 모듈** 을 사용하고 있으며, 22개의 층으로 구성되어있음. 앞에 나온 구조들보다 층수가 많으나, 파라미터 수는 VGGNet의 1/12에 불과함.
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-15.png"></img></br>  

GoogLeNet은 3개의 파트로 나눠짐.      
- **A: 특징 학습 구조(합성곱층 + 최대 풀링층)**     
- **B: 9개의 인셉션 모듈**    
인셉션 모듈 2개 + 풀링층 + 인셉션 모듈 5개 + 풀링층 + 인셉션 모듈 2개     
- **C: 분류기 구조(전결합층 + 소프트맥스층)**       
</br>

#### 하이퍼파라미터
- 학습률: 초기 학습률 0.01, 8에포크마다 학습률 4% 감소.    
- 최적화 알고리즘: 경사하강법      
- 모멘텀: 0.9     

GoogLeNet의 이미지넷 학습 Top-5 오차율은 6.67%로, 사람의 필적하는 성능(5%)를 보임.     
</br></br></br>


## 5-6. ResNet(Residual Neurual Network)
연구와 발전으로, 신경망의 층수가 많을수록 이미지에서 더 좋은 특징을 추출할 수 있다는 것을 발견함(다양한 추상화 수준의 특징 학습 가능). 때문에, ResNet에 층수를 많이 쌓음(50층, 101층, 152층).     
신경망 층수 증가로 발생하는 과적합 문제, 기울기 소실 문제를 해결하기 위해 다양한 해결책이 사용됨.
</br>

- 과적합 문제: 드롭아웃, L2 규제화, 배치 정규화   
- 기울기 소실: 스킵 연결(잔차 블록)
</br>

과적합 문제 해결을 위한 강한 배치 정규화 적용으로, 깊은 신경망의 복잡도를 VGGNet19보다 낮출 수 있음.    
</br>

### ■ 스킵 연결과 잔차 블록
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-20.png"></img></br> 

스킵 연결이란, 뒷층의 기울기값(정보)을 앞층에 직접 전달하는 별도의 경로를 추가하는 방법임.     
</br>

x = 뒷층의 기울기값, f(x) = 학습 방향을 따라 계산된 출력값이라고 하면, 스킵 연결로 앞층에 전달되는 기울기는 f(x) + x임. 따라서, 학습 시 앞의 항등함수를 학습하는 형태가 되고, 층이 많이 쌓여도 앞층보다 성능이 하락되지 않도록 함.      
합성곱층에 스킵 연결을 추가한 구조를 잔차 블록(Residual block)이라 함.
</br>

#### ResNet 구조
여러개의 잔차 블록이 늘어선 형태로 구성된 구조로, 이미지넷 분류 문제 Top-5 오차율 4.49%를 달성함. (앙상블 모델은 3.57%)    
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-21.png"></img></br>  

- 특징 추출기(합성곱층 + 풀링층, 그 뒤에 잔차 블록 한개 이상)   
- 분류기(전결합층 + 소프트맥스)     
</br>

#### ResNet 잔차 블록     
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-22.png"></img></br>  

활성화 함수는 ReLU를 사용.     
- **주경로**    
일련의 합성곱 연산 및 활성화 함수. 3개의 합성곱층으로 구성, 과적합 방지와 학습 속도 향상을 위해 각 합성곱층마다 배치 정규화 적용.       
경로의 구조는 {CONV → BN → ReLU] x 3     
- **지름길 경로**      
입력을 주 경로에서 합성곱층의 활성화 함수 바로 앞에 전달.      
</br>
지름길 경로 값 + 주 경로의 값 → ReLU함수에 통과     
</br>
차원 축소가 적용되면 이를 병목 잔차 블록(Bottleneck residual block)이라 하며, 여러 층에 걸쳐 입출력의 차원 제어 가능.    
</br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_5-23.png"></img></br> 

주 경로와 지름길 경로로 전달되는 정보의 차원이 동일해야 행렬 덧셉이 가능하기 때문에, 각 경로에서 나오는 결과값에 각각 차원 축소를 적용시킴.(= 축소 지름길 경로, Reduce shortcut)   
</br>

- 주 경로    
풀링층이 없고, 대신 1 X 1 합성곱층으로 다운샘플링 적용.    
잔차 블록 처음에 1 X 1 합성곱을 배치하고, 출력에 3 X 3, 1 X 1 합성곱을 하나씩 배치해서 두 번에 걸쳐 차원을 축소함.(각 합성곱층에 배치 정규화를 적용)
</br>

- 지름길 경로     
병목층 적용(1 X 1 합성곱층 + 배치정규화)
</br>

#### 하이퍼파라미터     
- 모멘텀 0.9    
- 학습률 초기값 0.1, 검증 오차 감소 없으면 학습률 1/10 감소    
- 가중치 감쇠율 0.0001    
- L2 규제화 함께 사용    

