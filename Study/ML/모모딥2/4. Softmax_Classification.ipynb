{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpzcRziiNfmB"
   },
   "source": [
    "# **Softmax Classification**\n",
    "--------\n",
    "Max ê°’ì„ Softí•˜ê²Œ ë¶™ì—¬ì¤˜ìš”! ì™€!\n",
    "\n",
    "## **SoftMax**\n",
    "ë¶„í¬ì˜ ì¢…ë¥˜ë¡œëŠ”, í•¨ìˆ˜ì˜ ë©´ì ì´ í™•ë¥  ê°’ì„ ë‚˜íƒ€ë‚´ëŠ” ì •ê·œë¶„í¬ë„ ìˆê³ , íŠ¹ì • ë²”ìœ„ì—ì„œ(ì ) ê°’ì´ ì¼ì •í•œ ê· ë“± ë¶„í¬(Uniform Distribution)ë„ ìˆë‹¤.   \n",
    "ê· ë“± ë¶„í¬ë¥¼ ê°€ì§„ ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ, SoftMax í™œì„±í™” í•¨ìˆ˜ë¥¼ ì¨ì„œ í™•ë¥ ì„ êµ¬í•˜ê²Œ ëœë‹¤!\n",
    "<br>\n",
    "\n",
    "#### **ê· ë“± ë¶„í¬ì˜ ì˜ˆ)**\n",
    "- **ì£¼ì‚¬ìœ„ ë˜ì§€ê¸°(ì´ì‚° ê· ë“± ë¶„í¬)**\n",
    "    - í™•ë¥  í•¨ìˆ˜ê°€ ì •ì˜ëˆ ëª¨ë“  ê³³ì—ì„œ ê·¸ ê°’ì´ ì¼ì •í•œ ë¶„í¬\n",
    "    - AëŠ” 0.7ì˜ í™•ë¥ ë¡œ ë¬´ì¡°ê±´(?) ê°€ìœ„ë¥¼ ë‚¸ë‹¤\n",
    "- **ì£¼ì‚¬ìœ„ ë˜ì§€ê¸°(ì—°ì† ê· ë“± ë¶„í¬)**\n",
    "    - íŠ¹ì • ë²”ìœ„ ë‚´ì—ì„œ í™•ë¥ ì´ ê· ë“±í•˜ê²Œ ë¶„í¬\n",
    "    - ì£¼ì‚¬ìœ„ë¥¼ ë˜ì¡Œì„ ë•Œ ìˆ«ì 6ì´ ë‚˜ì˜¬ í™•ë¥ ì€ 1/6\n",
    "<br><br>\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´, ì¹œêµ¬ë‘ ë§¤ì¼ ì²œì› ë‚´ê¸°ë¥¼ ê°€ìœ„ë°”ìœ„ë³´ ì‚¼ì„¸íŒìœ¼ë¡œ í•œë‹¤ê³  ì¹˜ì.   \n",
    "ê·¼ë° ë‚´ê°€ ë§¨ë‚  ì§„ë‹¤...... ë¶„í•˜ë‹¤   \n",
    "ê·¸ë˜ì„œ ì´ ìì‹ì„ ê´€ì°°í•´ ë³´ë‹ˆ ê°€ìœ„ë¥¼ ì œì¼ ì˜ ëƒˆë‹¤.   \n",
    "ë…ì´ ì˜¤ë¥¸ ë‚˜ëŠ” ì–˜ê°€ ê°€ìœ„ë¥¼ ëƒˆì„ ë•Œ, ë‹¤ìŒì— ì–´ë–¤ ê±¸ ë‚¼ì§€ í™•ë¥ ì„ ê³„ì‚°í•´ì„œ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ê²ƒì„ ë‚´ë ¤ê³  í•œë‹¤.   \n",
    "ì¹œêµ¬ê°€ ê°€ìœ„ë¥¼ ë‚¸ ë‹¤ìŒì— ê°ê° ê°€ìœ„, ë°”ìœ„, ë³´ë¥¼ ë‚´ëŠ” í™•ë¥ ì˜ ë¶„í¬ê°€ ìˆì„ê±´ë°...   \n",
    "ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ê·¸ í™•ë¥  ë¶„í¬ì™€ ë¹„ìŠ·í•˜ê²Œ ê·¼ì‚¬í•˜ê³  ì‹¶ë‹¤!! ì´ ë°©ë²•ìœ¼ë¡œ ìµœëŒ€ê°’ì„ ì†Œí”„íŠ¸í•˜ê²Œ ë½‘ì•„ ë‚´ëŠ” ê±°ì•¼!!  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;ğŸ‘‰ **SoftMax**\n",
    "<br>\n",
    "<br>\n",
    "ì¦‰, ì–´ë–¤ ê· ë“±í•œ í™•ë¥  ë¶„í¬ê°€ ì¡´ì¬í•  ë•Œ, ê° ì ì—ì„œì˜ í™•ë¥  ê°’ì„ ì ì ˆí•œ ë¹„ìœ¨ë¡œ ë‚˜íƒ€ë‚¸ë‹¤.  \n",
    "ì´ ë¹„ìœ¨ë“¤ì„ ë‹¤ ë”í•˜ë©´ 1ì´ ë¨!!(Sigmoidì™€ ë‹¤ë¥¸ ì !!)   \n",
    "SoftMaxë¥¼ ëª¨ë¸ì˜ ë§¨ ë§ˆì§€ë§‰ ì¸µìœ¼ë¡œ ê¹”ë©´, ê°ê°ì˜ í™•ë¥  ê°’ì„ ì–»ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë‹¤ì¤‘ ë¶„ë¥˜ ë¬¸ì œì— ì‚¬ìš©ëœë‹¤.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibR7YQLNNT3z",
    "outputId": "b2944115-567f-4f72-e726-bfdd49ee63fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "z = torch.FloatTensor([1, 2, 3]) #ë§Œì•½ ë‹¨ìˆœí•˜ê²Œ ê°€ì¥ í° ê°’ë§Œ ë½‘ì•˜ë‹¤ë©´, í•´ë‹¹ í™•ë¥ ì€ (0, 0, 1)ì´ ë  ê²ƒì„. í•˜ì§€ë§Œ ì†Œí”„íŠ¸ ë§¥ìŠ¤ëŠ” ê·¸ëŸ¬ì§€ ì•Šì§€\n",
    "hypothesis = F.softmax(z, dim = 0) #ì—´ ë°©í–¥ìœ¼ë¡œ í™•ë¥ ì˜ í•©ì´ 1ì´ ë¨\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f95Cqiy7lfER",
    "outputId": "90c0c3da-797b-44dc-89a7-3c014682be74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2R1c098lnW8"
   },
   "source": [
    "## **Cross Entropy**\n",
    "2ê°œì˜ í™•ë¥  ë¶„í¬ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ê·¸ í™•ë¥  ë¶„í¬ë“¤ì´ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ” ìˆ˜ì¹˜.   \n",
    "ê·¼ì‚¬í•˜ê³  ì‹¶ì€ í™•ë¥  ë¶„í¬ë¥¼ í–¥í•´ ì°¨ì´ë¥¼ ì¤„ì—¬ë‚˜ê°„ë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b_bhYfvqQrY"
   },
   "source": [
    "### **Cross Entropy Loss(Low-level)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMgX5zHQlfgM",
    "outputId": "b92fa32a-fc52-41c8-9391-0573e130edbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2025, 0.2176, 0.2324, 0.1142, 0.2333],\n",
      "        [0.1503, 0.1465, 0.2203, 0.1962, 0.2866],\n",
      "        [0.1473, 0.1262, 0.2831, 0.1827, 0.2607]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.rand(3, 5, requires_grad=True)\n",
    "hypothesis = F.softmax(z, dim=1) #í–‰ì„ ê¸°ì¤€ìœ¼ë¡œ ë”í•´ì„œ 1\n",
    "print(hypothesis) #ì˜ˆì¸¡ê°’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFpfF5JlpSJc",
    "outputId": "36180eb9-9985-4c6b-b05e-cc4b7c4956a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "#ì•„ë¬´ ìˆ˜ë‚˜ ë½‘ì•„ì„œ ì •ë‹µ ë§Œë“¤ê¸°\n",
    "y= torch.randint(5, (3,)).long()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtF1rb74qapo",
    "outputId": "08f575ef-3cd1-4539-ca2e-d3ddf5175d3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ì •ë‹µì„ one-hot vector í˜•íƒœë¡œ ë‚˜íƒ€ë‚´ê³ , ì •ë‹µ ì¸ë±ìŠ¤ì— 1ì„, ë‚˜ë¨¸ì§€ì— 0ì„ ë¿Œë¦°ë‹¤.\n",
    "y_one_hot = torch.zeros_like(hypothesis)#(3, 5)\n",
    "y_one_hot.scatter_(1, y.unsqueeze(1), 1) #(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qia1hdaBsOhS",
    "outputId": "3d475223-302d-4c19-990c-2d76d5121b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4572, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = (y_one_hot * - torch.log(hypothesis)).sum(dim=1).mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icpElYLu1kfJ"
   },
   "source": [
    "### **Cross-Entropy Loss with torch.nn.functional**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a6mGnUJ15y8",
    "outputId": "785bf99e-8c0c-4806-e9e4-5e345fa55e17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5971, -1.5252, -1.4591, -2.1701, -1.4553],\n",
       "        [-1.8948, -1.9205, -1.5129, -1.6285, -1.2496],\n",
       "        [-1.9153, -2.0702, -1.2618, -1.6998, -1.3445]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -torch.log(hypothesis)ì™€ ê°™ì€ ê²°ê³¼\n",
    "torch.log(F.softmax(z, dim=1))\n",
    "#ì•„ë˜ì™€ ê°™ì´ í•˜ë‚˜ë¡œ ì¤„ì¼ ìˆ˜ ìˆë‹¤\n",
    "F.log_softmax(z, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1gyC6JN2NHz",
    "outputId": "d1fcbf27-5860-41ed-b9e9-a82a0c85555a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4572, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(y_one_hot * -torch.log(F.softmax(z, dim=1)))ì™€ ê°™ë‹¤\n",
    "F.nll_loss(F.log_softmax(z, dim=1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGM16dIy3jZA",
    "outputId": "29ba6207-7439-4c04-b29a-b145bfecf2a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4572, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F.softmaxì™€ F.nll_lossë¥¼ í•©ì¹œ í•¨ìˆ˜ëŠ” F.cross_entropy()ì„\n",
    "F.cross_entropy(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjUbWkul4EGn"
   },
   "source": [
    "### **Training with Low-level Cross Entropy loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oCc6kfQ94fS8"
   },
   "outputs": [],
   "source": [
    "#labelì€ 0, 1, 2\n",
    "x_train = [[1, 2, 1, 1], # ì—¬ê¸°ì„œëŠ” (8, 4)ì§€ë§Œ, (m, 4)ê°œê°€ ìˆë‹¤ê³  ì³ë³´ì (mì€ í° ìˆ˜)\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]]\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0] #(m,)\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5Y366xu4zVG",
    "outputId": "6df1111c-3f77-4080-f53b-df1e27bdf900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/1000 Cost: 0.902463\n",
      "Epoch  200/1000 Cost: 0.839531\n",
      "Epoch  300/1000 Cost: 0.808064\n",
      "Epoch  400/1000 Cost: 0.788631\n",
      "Epoch  500/1000 Cost: 0.774939\n",
      "Epoch  600/1000 Cost: 0.764541\n",
      "Epoch  700/1000 Cost: 0.756266\n",
      "Epoch  800/1000 Cost: 0.749461\n",
      "Epoch  900/1000 Cost: 0.743724\n",
      "Epoch 1000/1000 Cost: 0.738794\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "\n",
    "for epoch in range(1, nb_epochs+1):\n",
    "    hypothesis = F.softmax(x_train.matmul(W)+b, dim = 1)\n",
    "    y_one_hot = torch.zeros_like(hypothesis)\n",
    "    y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
    "    cost = (y_one_hot * - torch.log(F.softmax(hypothesis, dim=1))).sum(dim=1).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100ë²ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8FrWKV65ORp"
   },
   "source": [
    "### **Training with F.cross_entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZRz2SJb7ukN",
    "outputId": "995831bc-2284-42c2-8df2-6c823cf7a1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/1000 Cost: 0.714269\n",
      "Epoch  200/1000 Cost: 0.638430\n",
      "Epoch  300/1000 Cost: 0.591185\n",
      "Epoch  400/1000 Cost: 0.554105\n",
      "Epoch  500/1000 Cost: 0.522028\n",
      "Epoch  600/1000 Cost: 0.492792\n",
      "Epoch  700/1000 Cost: 0.465232\n",
      "Epoch  800/1000 Cost: 0.438588\n",
      "Epoch  900/1000 Cost: 0.412274\n",
      "Epoch 1000/1000 Cost: 0.385798\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(1, nb_epochs+1):\n",
    "    z = x_train.matmul(W) + b\n",
    "    cost = F.cross_entropy(z, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100ë²ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpxYDInc6qT2"
   },
   "source": [
    "### **High-level Implementation with nn.Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4QIk8cn6zgz",
    "outputId": "83fb9ef3-bd3e-434a-99a9-9162ebf8ac12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100/1000 Cost: 0.708336\n",
      "Epoch  200/1000 Cost: 0.626136\n",
      "Epoch  300/1000 Cost: 0.569848\n",
      "Epoch  400/1000 Cost: 0.520366\n",
      "Epoch  500/1000 Cost: 0.473517\n",
      "Epoch  600/1000 Cost: 0.427770\n",
      "Epoch  700/1000 Cost: 0.382397\n",
      "Epoch  800/1000 Cost: 0.337085\n",
      "Epoch  900/1000 Cost: 0.292189\n",
      "Epoch 1000/1000 Cost: 0.251781\n"
     ]
    }
   ],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = SoftmaxClassifierModel()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(1, nb_epochs+1):\n",
    "    prediction = model(x_train)\n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100ë²ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
