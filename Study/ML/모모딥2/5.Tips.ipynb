{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Tips**\n",
        "--------\n",
        "\n",
        "## **Maximum Likelihood Estimation(MLE)**\n",
        "학습을 반복적으로 진행하면서, 예측값의 확률 분포를 정답 확률 분포와 비슷하게 만들어 나가는 과정(Loss 설정, Cross Entropy).\n",
        "\n",
        "**최대 우도 추정**    \n",
        "**❓ Likelihood(우도)란?**   \n",
        "<br>\n",
        "p(data | distribution) = Probabilty   \n",
        "p(distribution | data) = Likelihood   \n",
        "<br>\n",
        "즉, 입력 data가 고정되어 있을 때, 분포가 변화함.  \n",
        "어떤 분포가 가장 data를 잘 설명하는가?\n",
        "\n",
        "Parameter를 ϴ라고 할 때\n",
        "$$ L(ϴ) = p(X|ϴ) $$\n",
        "로 표현할 수 있다.\n",
        "\n",
        "**❓ 그렇다면 MLE란?**   \n",
        "ϴ를 추정하는 방법.   \n",
        "Sample을 모듀 평균 값으로 지정해 Likelihood가 가장 큰 지점을 찾는다.   \n",
        "\n",
        "예로, 압정이 있다고 치면\n",
        "<br>\n",
        "뾰족한 곳이 위로 = Class 1   \n",
        "뾰족한 곳이 바닥 쪽으로 = Class 2    \n",
        "<br>\n",
        "로 나타낼 수 있다. 이런 확률 분포를 이항 분호, 베르누이 분포라고 한다.   \n",
        "<br>\n",
        "\n",
        "관찰 값이 있을 때, 압정이 Class 1이 되는 확률 분포, 압정이 Class 2r가 되는 확률 분포를 알고싶다!! 👉 MLE를 통해 예측   \n",
        "<br>\n",
        "\n",
        "즉, Observation을 가장 잘 설명하는 parameter(Observation이 Local Maxima가 되는!)를 찾아내는 과정 = MLE\n",
        "\n",
        "그 점을 어떻게 찾죠?   \n",
        "기울기를 구합니다.    \n",
        "➡ Gradient Ascent 수행    \n",
        "➡ Gradien Descent로 수행해도 과정은 같다   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OpzcRziiNfmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Overfitting**\n",
        "**[지난 이야기]**   \n",
        "Gradient desent를 통한 최적화로 주어진 data를 가장 잘 설명하는 parameter를 찾게 되었다.   \n",
        "하지만, MLE는 숙명적으로 Overfitting이 발생할 수 밖에 없게 되는데...   \n",
        "\n",
        "**❓ Overffiting이란?**   \n",
        "학습 data에 과도하게 경계선이 fitting 되버린 상황을 말함.\n",
        "<br>\n",
        "\n",
        "### **Overffiting 발생 여부 확인**\n",
        "보통 dataset을 Training set, Test set으로 나눈다.(8, 2)   \n",
        "더 나아가, Training set, Validation set, Test set(6, 2, 2)로 나누기도 한다.\n",
        "<br>\n",
        "\n",
        "**⚡Training set**:   \n",
        "모델의 학습을 위한 dataset   \n",
        "**⚡Validation set**:    \n",
        "모델을 overffiting이 일어날 때 까지 학습한 후, Overfitting이 일어나기 바로 이전 지점(Baseline)에 해당하는 epoch 찾기 위해 사용되는 dataset.    \n",
        "**⚡Test set**:     \n",
        "모델 성능 평가를 위한 dataset. 전 단꼐에서 구한 epoch까지 진행, 학습에 관여하지 않음.    \n",
        "\n",
        "Training set, Validation set, Test set 모두 비슷한 확률 분포를 가졌기 때문에, Training set이 오버피팅 되었는지 Validation set, Test set을 가지고 확인할 수 있다.\n",
        "<br>\n",
        "\n",
        "하지만 각각의 dataset을 가지고 너무 많이 돌리면, 모든 dataset들에 대해 overfitting이 발생할 수 있으니 주의!\n",
        "<br><br>\n",
        "\n",
        "### **Overfitting을 어떻게 최소화 할까?**\n",
        "- More data\n",
        "    - Data 수가 적을수록 편향된 결과를 얻음\n",
        "- Less features\n",
        "    - feature 수가 많아 복잡해질 경우에도 생길 가능성 높아짐\n",
        "- **⭐ Regularization**\n",
        "<br>\n",
        "\n",
        "## **Regularization 방법**\n",
        "- Early Stopping\n",
        "    - Validation loss가 더 이상 낮아지지 않을 때 그냥 멈추기\n",
        "- Reducing Network Size\n",
        "- Weight Decay\n",
        "    - Weight의 크기를 제한\n",
        "- **⭐Dropout**\n",
        "- **⭐Batch Nomalization**\n",
        "\n",
        "<br>\n",
        "\n",
        "### **Basic Approach to Train DNN**\n",
        "1. Make a neural network architecture.\n",
        "2. Train and check that model is over-fitted(overfitting 일어날 때 까지)   \n",
        "        a. If it is not, increase th model size(deeper and wider).   \n",
        "        b. If it is, add regularization, such as drop-out, batch-nomalization.   \n",
        "3. Repeat from step-2   "
      ],
      "metadata": {
        "id": "maJSJNb0VDdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "3D2hJMiunot_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ibR7YQLNNT3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbff576e-b5bd-49e5-e24d-922bf2c91cfa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x788a44109450>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Test Dataset"
      ],
      "metadata": {
        "id": "dJM1QXvvoVoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor([[1, 2, 1],\n",
        "                             [1, 3, 2],\n",
        "                             [1, 3, 4],\n",
        "                             [1, 5, 5],\n",
        "                             [1, 7, 5],\n",
        "                             [1, 2, 5],\n",
        "                             [1, 6, 6],\n",
        "                             [1, 7, 7]]) # |x_train| = (m, 3)\n",
        "y_train = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0]) #|y_traini| = (m,)"
      ],
      "metadata": {
        "id": "t-8b64EXoRpw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = torch.FloatTensor([[2, 1, 1], [3, 1, 2], [3, 3, 4]])\n",
        "y_test = torch.LongTensor([2, 2, 2])"
      ],
      "metadata": {
        "id": "jGCMzQdEkko1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "ksAbk04mlE4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = SoftmaxClassifierModel()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "SjhLN-L9lGk0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "8Gv9E_Byl7VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, x_train, y_train):\n",
        "    nb_epochs = 20\n",
        "    for epoch in range(1, nb_epochs):\n",
        "        prediction = model(x_train)\n",
        "\n",
        "        cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))\n"
      ],
      "metadata": {
        "id": "Wzm54dQ0mAjz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test(Validation)\n"
      ],
      "metadata": {
        "id": "DwwgYMQmR9fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, optimizer, x_test, y_test):\n",
        "    prediction = model(x_test)\n",
        "    print(prediction)\n",
        "    predicted_classes = prediction.max(1)[1]\n",
        "    print(prediction.max(1))\n",
        "    correct_count = (predicted_classes == y_test).sum().item()\n",
        "    cost = F.cross_entropy(prediction, y_test)\n",
        "\n",
        "    print('Accuracy: {}% Cost {:.6f}'.format(correct_count/len(y_test)* 100,  cost.item()))\n"
      ],
      "metadata": {
        "id": "u5W3jnd7SGYl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "IDYfD3uHS7rF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, optimizer, x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NRHTCemTELE",
        "outputId": "47ba6481-2b73-40f5-aecd-7c01c1a01b9d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    1/20 Cost: 0.825861\n",
            "Epoch    2/20 Cost: 0.822643\n",
            "Epoch    3/20 Cost: 0.819480\n",
            "Epoch    4/20 Cost: 0.816369\n",
            "Epoch    5/20 Cost: 0.813311\n",
            "Epoch    6/20 Cost: 0.810303\n",
            "Epoch    7/20 Cost: 0.807343\n",
            "Epoch    8/20 Cost: 0.804431\n",
            "Epoch    9/20 Cost: 0.801565\n",
            "Epoch   10/20 Cost: 0.798744\n",
            "Epoch   11/20 Cost: 0.795967\n",
            "Epoch   12/20 Cost: 0.793232\n",
            "Epoch   13/20 Cost: 0.790539\n",
            "Epoch   14/20 Cost: 0.787887\n",
            "Epoch   15/20 Cost: 0.785274\n",
            "Epoch   16/20 Cost: 0.782700\n",
            "Epoch   17/20 Cost: 0.780164\n",
            "Epoch   18/20 Cost: 0.777664\n",
            "Epoch   19/20 Cost: 0.775200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, optimizer, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoseN12HUL-2",
        "outputId": "5720cc42-e069-421e-f8d2-688d4f624644"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.1730, -0.4375,  2.0221],\n",
            "        [-1.3396, -0.4462,  2.6016],\n",
            "        [-0.9965, -0.3337,  1.7039]], grad_fn=<AddmmBackward0>)\n",
            "torch.return_types.max(\n",
            "values=tensor([2.0221, 2.6016, 1.7039], grad_fn=<MaxBackward0>),\n",
            "indices=tensor([2, 2, 2]))\n",
            "Accuracy: 100.0% Cost 0.121348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate\n"
      ],
      "metadata": {
        "id": "Nlu9omLNUHLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning rate가 너무 크면 diverge하면서 cost가 점점 늘어난다.(overshooting)"
      ],
      "metadata": {
        "id": "BGh7Th0KV0ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 1e5)\n",
        "\n",
        "train(model, optimizer, x_train, y_train)\n",
        "#Cost가 값이 커졌어요"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkhO3V34VzWt",
        "outputId": "87980082-71d6-4fcd-f747-2d11a134e826"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    1/20 Cost: 3.187324\n",
            "Epoch    2/20 Cost: 1100707.250000\n",
            "Epoch    3/20 Cost: 2482261.250000\n",
            "Epoch    4/20 Cost: 664769.812500\n",
            "Epoch    5/20 Cost: 1668198.750000\n",
            "Epoch    6/20 Cost: 748657.875000\n",
            "Epoch    7/20 Cost: 1353832.250000\n",
            "Epoch    8/20 Cost: 1790073.750000\n",
            "Epoch    9/20 Cost: 917894.812500\n",
            "Epoch   10/20 Cost: 989687.125000\n",
            "Epoch   11/20 Cost: 990845.375000\n",
            "Epoch   12/20 Cost: 1585082.375000\n",
            "Epoch   13/20 Cost: 1265073.750000\n",
            "Epoch   14/20 Cost: 1149144.875000\n",
            "Epoch   15/20 Cost: 589766.937500\n",
            "Epoch   16/20 Cost: 689678.500000\n",
            "Epoch   17/20 Cost: 983032.875000\n",
            "Epoch   18/20 Cost: 1265073.750000\n",
            "Epoch   19/20 Cost: 1686644.750000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning rate가 너무 작으면 cost가 거의 줄어들지 않는다."
      ],
      "metadata": {
        "id": "6cgHhzC8XQvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 1e-10)\n",
        "\n",
        "train(model, optimizer, x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSuPE_WfXXnV",
        "outputId": "a0201462-0568-4f31-c902-996a4642b5f0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    1/20 Cost: 1.341574\n",
            "Epoch    2/20 Cost: 1.341574\n",
            "Epoch    3/20 Cost: 1.341574\n",
            "Epoch    4/20 Cost: 1.341574\n",
            "Epoch    5/20 Cost: 1.341574\n",
            "Epoch    6/20 Cost: 1.341574\n",
            "Epoch    7/20 Cost: 1.341574\n",
            "Epoch    8/20 Cost: 1.341574\n",
            "Epoch    9/20 Cost: 1.341574\n",
            "Epoch   10/20 Cost: 1.341574\n",
            "Epoch   11/20 Cost: 1.341574\n",
            "Epoch   12/20 Cost: 1.341574\n",
            "Epoch   13/20 Cost: 1.341574\n",
            "Epoch   14/20 Cost: 1.341574\n",
            "Epoch   15/20 Cost: 1.341574\n",
            "Epoch   16/20 Cost: 1.341574\n",
            "Epoch   17/20 Cost: 1.341574\n",
            "Epoch   18/20 Cost: 1.341574\n",
            "Epoch   19/20 Cost: 1.341574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "적절한 숫자로 시작해 발산하면 작게, Cost가 줄지 않으면 크게 조정합시다"
      ],
      "metadata": {
        "id": "koWBMMDnXlW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
        "#Tip\n",
        "#일단 1e-1부터 해서 어 괜찮네? 어 발산하네? 이런거 확인하고 조금씩 조정하는 것 추천\n",
        "\n",
        "train(model, optimizer, x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEm9zzlMXuiE",
        "outputId": "c967e5f5-94d2-41c3-ff55-87f73ef62539"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    1/20 Cost: 2.939317\n",
            "Epoch    2/20 Cost: 1.887239\n",
            "Epoch    3/20 Cost: 1.055398\n",
            "Epoch    4/20 Cost: 0.936401\n",
            "Epoch    5/20 Cost: 0.917493\n",
            "Epoch    6/20 Cost: 0.911811\n",
            "Epoch    7/20 Cost: 0.906384\n",
            "Epoch    8/20 Cost: 0.901102\n",
            "Epoch    9/20 Cost: 0.895959\n",
            "Epoch   10/20 Cost: 0.890947\n",
            "Epoch   11/20 Cost: 0.886062\n",
            "Epoch   12/20 Cost: 0.881298\n",
            "Epoch   13/20 Cost: 0.876650\n",
            "Epoch   14/20 Cost: 0.872114\n",
            "Epoch   15/20 Cost: 0.867685\n",
            "Epoch   16/20 Cost: 0.863359\n",
            "Epoch   17/20 Cost: 0.859132\n",
            "Epoch   18/20 Cost: 0.855000\n",
            "Epoch   19/20 Cost: 0.850961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "It_PjntmYq95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression 문제\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                            [93, 88, 93],\n",
        "                            [89, 91, 90],\n",
        "                            [96, 98, 100],\n",
        "                            [73, 66, 70]]) #|x_train| = (m, 3)\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]]) #|y_train|=(m,))"
      ],
      "metadata": {
        "id": "l-kis2gPYtoQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규 표준화로 전처리를 해 준다.\n",
        "# Gradient Descent 기반의 최적화 알고리즘들은\n",
        "#데이터의 스케일에 민감하다.\n",
        "#정규화를 통해 입력 데이터의 스케일을 조절하면\n",
        "#학습이 안정적으로 이루어질 가능성이 높아진다.\n",
        "\n",
        "mu = x_train.mean(dim=0)\n",
        "sigma = x_train.std(dim=0)\n",
        "norm_x_train = (x_train - mu) /sigma\n",
        "print(norm_x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRXCO2RbhuYd",
        "outputId": "0f75b839-33da-46fd-b8ec-2ae0f9e988d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0674, -0.3758, -0.8398],\n",
            "        [ 0.7418,  0.2778,  0.5863],\n",
            "        [ 0.3799,  0.5229,  0.3486],\n",
            "        [ 1.0132,  1.0948,  1.1409],\n",
            "        [-1.0674, -1.5197, -1.2360]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with Preprocessed Data\n",
        "학습이 더 잘 되는 것을 볼 수 있다."
      ],
      "metadata": {
        "id": "BYq7wnzxhvGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = MultivariateLinearRegressionModel()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 1e-1)"
      ],
      "metadata": {
        "id": "tfCi16cninBc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, x_train, y_train):\n",
        "    nb_epochs = 20\n",
        "    for epoch in range(1, nb_epochs):\n",
        "        prediction = model(x_train)\n",
        "        cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))\n"
      ],
      "metadata": {
        "id": "Neb524PsjOh8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, optimizer, norm_x_train, y_train) #아니 망했는데...?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkV6K120j-b8",
        "outputId": "3135648c-4746-4fda-e55c-6e0def579e13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    1/20 Cost: -0.000000\n",
            "Epoch    2/20 Cost: -0.000000\n",
            "Epoch    3/20 Cost: -0.000000\n",
            "Epoch    4/20 Cost: -0.000000\n",
            "Epoch    5/20 Cost: -0.000000\n",
            "Epoch    6/20 Cost: -0.000000\n",
            "Epoch    7/20 Cost: -0.000000\n",
            "Epoch    8/20 Cost: -0.000000\n",
            "Epoch    9/20 Cost: -0.000000\n",
            "Epoch   10/20 Cost: -0.000000\n",
            "Epoch   11/20 Cost: -0.000000\n",
            "Epoch   12/20 Cost: -0.000000\n",
            "Epoch   13/20 Cost: -0.000000\n",
            "Epoch   14/20 Cost: -0.000000\n",
            "Epoch   15/20 Cost: -0.000000\n",
            "Epoch   16/20 Cost: -0.000000\n",
            "Epoch   17/20 Cost: -0.000000\n",
            "Epoch   18/20 Cost: -0.000000\n",
            "Epoch   19/20 Cost: -0.000000\n"
          ]
        }
      ]
    }
  ]
}
