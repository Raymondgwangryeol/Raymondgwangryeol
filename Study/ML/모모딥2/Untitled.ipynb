{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Perceptron**\n",
        "--------\n",
        "인공신경망(Neuron)의 한 종류.\n",
        "\n",
        "## **Neuron?**\n",
        "동물 신경계, 특히 인간의 뇌의 뉴런을 본 따 만든 망을 뉴런(인공 신경망)이라고 함.   \n",
        "\n",
        "**뉴런의 동작 원리**   \n",
        "1. **입력 신호의 총량이 threshold를 넘으면** 뉴런이 활성화 됨.\n",
        "2. 활성화 된 뉴런은 신호를 다른 뉴런으로 전달.\n",
        "3. 만약 입력 신호 총량이 threshold를 넘지 못하면, 신호가 다음 뉴런으로 전달 되지 않음.\n",
        "\n",
        "## **Perceptron**\n",
        "Perceptron의 초창기 모델은 linear classifier로, AND, OR 문제를 해결하기 위해 만들어 졌다.   \n",
        "(2가지 class가 있을 때 이를 linear하게 분리하는)   \n",
        "\n",
        "1. 입력이 들어왔을 때\n",
        "2. 입력에 가중치들을 곱하게 되고\n",
        "3. 이 입력 값들이 가중치를 넘으면\n",
        "4. 활성화 함수(sigmoid 같은)를 거쳐서\n",
        "5. 최종적인 output이 나온다.\n",
        "\n",
        "## **Perceptron과 XOR**\n",
        "하하 AND, OR문제? 문제 없다! 무적이다! 아무나 와라!   \n",
        "XOR: 히히 과연 그럴까?   \n",
        "\n",
        "Winsky: 너네 1개 layer Perceptron으로는 XOR 문제 절대 못 푼다. 여러 layer를 쌓아야 풀 수 있음.   \n",
        "근데 각 층의 weight들 학습해야 하는데 너네 어떻게 할래?   \n",
        "절.대.못.할.걸   \n",
        "<br>\n",
        "\n",
        "1개 층의 Perceptron으로는 못 푼다는걸 직접 느껴봐요"
      ],
      "metadata": {
        "id": "BEDM5q60a2nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "X = torch.FloatTensor([[0, 0],[0, 1], [1, 0],[1, 1]])\n",
        "Y = torch.FloatTensor([[0],[1],[1],[0]])\n",
        "\n",
        "linear = torch.nn.Linear(2, 1, bias = True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "model = torch.nn.Sequential(linear, sigmoid).to(device)\n",
        "\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "for step in range(10001):\n",
        "    hypothesis = model(X)\n",
        "    cost = criterion(hypothesis, Y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(step, cost.item()) #특정 지점부터 cost값이 줄지 않기 시작"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNiHrrNOCEVG",
        "outputId": "80ffa929-9308-4a8b-8a3e-326bb8de35c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.6999189853668213\n",
            "100 0.6931477785110474\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931471824645996\n",
            "1300 0.6931471824645996\n",
            "1400 0.6931471824645996\n",
            "1500 0.6931471824645996\n",
            "1600 0.6931471824645996\n",
            "1700 0.6931471824645996\n",
            "1800 0.6931471824645996\n",
            "1900 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "2100 0.6931471824645996\n",
            "2200 0.6931471824645996\n",
            "2300 0.6931471824645996\n",
            "2400 0.6931471824645996\n",
            "2500 0.6931471824645996\n",
            "2600 0.6931471824645996\n",
            "2700 0.6931471824645996\n",
            "2800 0.6931471824645996\n",
            "2900 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "3100 0.6931471824645996\n",
            "3200 0.6931471824645996\n",
            "3300 0.6931471824645996\n",
            "3400 0.6931471824645996\n",
            "3500 0.6931471824645996\n",
            "3600 0.6931471824645996\n",
            "3700 0.6931471824645996\n",
            "3800 0.6931471824645996\n",
            "3900 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "4100 0.6931471824645996\n",
            "4200 0.6931471824645996\n",
            "4300 0.6931471824645996\n",
            "4400 0.6931471824645996\n",
            "4500 0.6931471824645996\n",
            "4600 0.6931471824645996\n",
            "4700 0.6931471824645996\n",
            "4800 0.6931471824645996\n",
            "4900 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "5100 0.6931471824645996\n",
            "5200 0.6931471824645996\n",
            "5300 0.6931471824645996\n",
            "5400 0.6931471824645996\n",
            "5500 0.6931471824645996\n",
            "5600 0.6931471824645996\n",
            "5700 0.6931471824645996\n",
            "5800 0.6931471824645996\n",
            "5900 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "6100 0.6931471824645996\n",
            "6200 0.6931471824645996\n",
            "6300 0.6931471824645996\n",
            "6400 0.6931471824645996\n",
            "6500 0.6931471824645996\n",
            "6600 0.6931471824645996\n",
            "6700 0.6931471824645996\n",
            "6800 0.6931471824645996\n",
            "6900 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "7100 0.6931471824645996\n",
            "7200 0.6931471824645996\n",
            "7300 0.6931471824645996\n",
            "7400 0.6931471824645996\n",
            "7500 0.6931471824645996\n",
            "7600 0.6931471824645996\n",
            "7700 0.6931471824645996\n",
            "7800 0.6931471824645996\n",
            "7900 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "8100 0.6931471824645996\n",
            "8200 0.6931471824645996\n",
            "8300 0.6931471824645996\n",
            "8400 0.6931471824645996\n",
            "8500 0.6931471824645996\n",
            "8600 0.6931471824645996\n",
            "8700 0.6931471824645996\n",
            "8800 0.6931471824645996\n",
            "8900 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "9100 0.6931471824645996\n",
            "9200 0.6931471824645996\n",
            "9300 0.6931471824645996\n",
            "9400 0.6931471824645996\n",
            "9500 0.6931471824645996\n",
            "9600 0.6931471824645996\n",
            "9700 0.6931471824645996\n",
            "9800 0.6931471824645996\n",
            "9900 0.6931471824645996\n",
            "10000 0.6931471824645996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    prediction = hypothesis.float() >= torch.FloatTensor([0.5])\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ',\n",
        "          predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v185992fEBxz",
        "outputId": "b5cd2765-764d-4894-8cb6-9d93a729eb76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hypothesis:  [[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]] \n",
            "Correct:  [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] \n",
            "Accuracy:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN에서 Forward Propagation으로 linear가 2개일 때 W1, W2, b1, b2를 구한다고 하면,\n",
        "$$linear1: K(X) = sigmoid(XW₁+B₁)$$\n",
        "$$linear2: H(X) = sigmoid(K(X)W₂+b₂))$$\n",
        "이런 식이 나올텐데, 이걸 어떻게 구하지..?\n",
        "\n",
        "## **Backpropagation**\n",
        "걱정 마세요 여러분 제가 해결해 드립니다(Chain rule)   \n",
        "Weight에 대한 Loss의 미분 값을 구하고, Loss값을 최소화 시킬 수 있도록 조정함.    \n",
        "편미분을 통해서 어떤 어려운 식이라도 간단하게 미분 가능!    \n",
        "<br><br>\n",
        "\n",
        "층을 더 쌓아봅시다!"
      ],
      "metadata": {
        "id": "AH57QFBzIhCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "X = torch.FloatTensor([[0, 0],[0, 1], [1, 0],[1, 1]])\n",
        "Y = torch.FloatTensor([[0],[1],[1],[0]])\n",
        "\n",
        "#nn.Linear 2층을 사용한다\n",
        "w1 = torch.Tensor(2, 2).to(device)\n",
        "b1 = torch.Tensor(2).to(device)\n",
        "w2 = torch.Tensor(2, 1).to(device)\n",
        "b2 = torch.Tensor(1).to(device)\n",
        "\n",
        "torch.nn.init.normal_(w1)\n",
        "torch.nn.init.normal_(b1)\n",
        "torch.nn.init.normal_(w2)\n",
        "torch.nn.init.normal_(b2)\n",
        "\n",
        "learning_rate =1\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + torch.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x): # 시그모이드 미분한 메서드\n",
        "    return sigmoid(x) * (1 - sigmoid(x))"
      ],
      "metadata": {
        "id": "wkjvrm3_YhAw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(10001):\n",
        "    l1 = torch.add(torch.matmul(X, w1), b1)\n",
        "    a1 = sigmoid(l1)\n",
        "    l2 = torch.add(torch.matmul(a1, w2), b2)\n",
        "    Y_pred = sigmoid(l2)\n",
        "\n",
        "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred)) # BCE Loss\n",
        "\n",
        "    #Back prop (chain rule)\n",
        "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
        "    d_l2 = d_Y_pred *sigmoid_prime(l2)\n",
        "    d_b2 = d_l2\n",
        "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
        "\n",
        "    d_a1 = torch.matmul(d_b2, torch.transpose(w2, 0, 1))\n",
        "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
        "    d_b1 = d_l1\n",
        "    d_w1 = torch.matmul(torch.transpose(X, 0, 1),d_b1)\n",
        "\n",
        "    w1 = w1 - learning_rate*d_w1\n",
        "    b1 = b1 - learning_rate*torch.mean(d_b1,0)\n",
        "    w2 = w2 - learning_rate*d_w2\n",
        "    b2 = b2 - learning_rate*torch.mean(d_b2,0)\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(step, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf0a6jWJbNIj",
        "outputId": "e40e115d-0793-410b-e5d7-38a399e9f486"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.6940568089485168\n",
            "100 0.281848669052124\n",
            "200 0.0478261262178421\n",
            "300 0.021345559507608414\n",
            "400 0.01334218867123127\n",
            "500 0.009612534195184708\n",
            "600 0.007480262778699398\n",
            "700 0.006107822991907597\n",
            "800 0.00515343900769949\n",
            "900 0.00445280596613884\n",
            "1000 0.0039172363467514515\n",
            "1100 0.003494983073323965\n",
            "1200 0.003153689205646515\n",
            "1300 0.0028723436407744884\n",
            "1400 0.002636490622535348\n",
            "1500 0.002435920527204871\n",
            "1600 0.002263369970023632\n",
            "1700 0.0021133646368980408\n",
            "1800 0.001981841865926981\n",
            "1900 0.0018655199091881514\n",
            "2000 0.001762002008035779\n",
            "2100 0.0016691621858626604\n",
            "2200 0.0015856071840971708\n",
            "2300 0.0015098856529220939\n",
            "2400 0.0014410398434847593\n",
            "2500 0.0013781121233478189\n",
            "2600 0.0013204144779592752\n",
            "2700 0.0012673037126660347\n",
            "2800 0.0012183014769107103\n",
            "2900 0.0011728692334145308\n",
            "3000 0.0011306634405627847\n",
            "3100 0.0010913999285548925\n",
            "3200 0.0010547498241066933\n",
            "3300 0.0010204592254012823\n",
            "3400 0.0009882738813757896\n",
            "3500 0.0009580745827406645\n",
            "3600 0.0009296368807554245\n",
            "3700 0.0009027967462316155\n",
            "3800 0.0008774941088631749\n",
            "3900 0.0008535797242075205\n",
            "4000 0.0008308446849696338\n",
            "4100 0.0008093782817013562\n",
            "4200 0.0007889268454164267\n",
            "4300 0.0007694753585383296\n",
            "4400 0.0007509492570534348\n",
            "4500 0.0007333334651775658\n",
            "4600 0.000716508598998189\n",
            "4700 0.0007003701757639647\n",
            "4800 0.0006849928176961839\n",
            "4900 0.0006702421815134585\n",
            "5000 0.000656162912491709\n",
            "5100 0.0006426209001801908\n",
            "5200 0.0006296159699559212\n",
            "5300 0.000617148180026561\n",
            "5400 0.0006051280070096254\n",
            "5500 0.0005935852532275021\n",
            "5600 0.0005824750987812877\n",
            "5700 0.0005717379972338676\n",
            "5800 0.0005614483961835504\n",
            "5900 0.0005514571676030755\n",
            "6000 0.0005418686196208\n",
            "6100 0.0005325934616848826\n",
            "6200 0.0005235718563199043\n",
            "6300 0.00051489332690835\n",
            "6400 0.0005064982688054442\n",
            "6500 0.0004983716644346714\n",
            "6600 0.0004905135137960315\n",
            "6700 0.00048284936929121614\n",
            "6800 0.0004754536203108728\n",
            "6900 0.00046826672041788697\n",
            "7000 0.00046130354166962206\n",
            "7100 0.00045456408406607807\n",
            "7200 0.00044794398127123713\n",
            "7300 0.0004415773437358439\n",
            "7400 0.0004353897529654205\n",
            "7500 0.0004293959937058389\n",
            "7600 0.0004234917869325727\n",
            "7700 0.0004177963128313422\n",
            "7800 0.00041223509470000863\n",
            "7900 0.00040682300459593534\n",
            "8000 0.0004015451413579285\n",
            "8100 0.00039640150498598814\n",
            "8200 0.00039139206637628376\n",
            "8300 0.00038647212204523385\n",
            "8400 0.0003817161777988076\n",
            "8500 0.00037704978603869677\n",
            "8600 0.00037254736525937915\n",
            "8700 0.00036810460733249784\n",
            "8800 0.00036378117511048913\n",
            "8900 0.00035953224869444966\n",
            "9000 0.0003554026479832828\n",
            "9100 0.0003513625415507704\n",
            "9200 0.000347411900293082\n",
            "9300 0.00034355069510638714\n",
            "9400 0.00033977898419834673\n",
            "9500 0.000336081808200106\n",
            "9600 0.00033247412648051977\n",
            "9700 0.00032892607850953937\n",
            "9800 0.0003254525945521891\n",
            "9900 0.00032206857576966286\n",
            "10000 0.00031872926047071815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((Y_pred> 0.5).float())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZN0UOiNsPn4",
        "outputId": "f9fb731f-b205-4abf-adaa-51bdf4982262"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code: xor-nn"
      ],
      "metadata": {
        "id": "vxNPhhuKszjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "X = torch.FloatTensor([[0, 0],[0, 1], [1, 0],[1, 1]])\n",
        "Y = torch.FloatTensor([[0],[1],[1],[0]])\n",
        "\n",
        "linear1 = torch.nn.Linear(2, 2, bias = True) # 두 개를 쌓았다\n",
        "linear2 = torch.nn.Linear(2, 1, bias = True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
        "\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "for step in range(10001):\n",
        "    hypothesis = model(X)\n",
        "    cost = criterion(hypothesis, Y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 1000 == 0:\n",
        "        print(step, cost.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFEsER8Hs6iU",
        "outputId": "a794e471-8209-4cad-de3f-5129554f0a3f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.7016617059707642\n",
            "1000 0.4316394329071045\n",
            "2000 0.018728366121649742\n",
            "3000 0.009086793288588524\n",
            "4000 0.005975094623863697\n",
            "5000 0.004445049446076155\n",
            "6000 0.003536670934408903\n",
            "7000 0.002935562049970031\n",
            "8000 0.0025085590314120054\n",
            "9000 0.0021896709222346544\n",
            "10000 0.001942584989592433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    prediction = hypothesis.float() >= torch.FloatTensor([0.5])\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ',\n",
        "          predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY4JyjBZtUg1",
        "outputId": "c8f8f377-e802-43dc-a1df-c6c366eeacff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hypothesis:  [[0.00169352]\n",
            " [0.99773765]\n",
            " [0.99772567]\n",
            " [0.00153141]] \n",
            "Correct:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:  1.0\n"
          ]
        }
      ]
    }
  ]
}