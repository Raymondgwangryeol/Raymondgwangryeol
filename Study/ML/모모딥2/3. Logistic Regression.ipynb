{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression**\n",
        "수학을 사용해서 두 데이터 요인간의 관계를 찾는 분석 기법.   \n",
        "예측도 Y/N과 같은 유한한 수를 가짐.(이름은 Regression이지만 사실 Binary Classification 문제)  \n",
        "</br>\n",
        "**예시)**  \n",
        "❔ 웹 쇼핑몰 방문자가 과연 결제 버튼을 누를까요?  \n",
        "&nbsp;&nbsp;&nbsp; Input = 웹 서핑 시간 + 카트에 담은 항목 수 + ..등등   \n",
        "&nbsp;&nbsp;&nbsp;Ouput = 누를까? 말까?   \n",
        "</br>\n",
        "### ⚡**장점**\n",
        "1. 다른 ML 모델보다 간단한 수식\n",
        "2. 대량의 data 고속 처리 가능\n",
        "    - 메모리 처리 및 성능과 같은 메모리 계산 용량이 덜 필요\n",
        "3. 전처리에도 사용 OK! 범위가 넓은 DATA를 작고 유한한 값 범위로 정렬\n",
        "4. 계산이 덜 복잡해서 오류 수정도 더 쉽다\n",
        "\n",
        "### ⚡**응용**\n",
        "- 제조\n",
        "    - 기계류의 부품이 고장날 확률 추정. 고장 나 안 나?\n",
        "- 의료\n",
        "    - 질병 발생 가능성 예측\n",
        "- 금융\n",
        "    - 사기 / NOT 사기\n",
        "- 마케팅\n",
        "    - 광고 클릭 / 클릭 안 함\n",
        "</br></br>\n",
        "\n",
        "### ⚡**활성화 함수: Logistic 함수**\n",
        "$$ H(X) = \\frac{1}{1+e^{-W^T X}} = \\frac{1}{1+e^{-XW}}$$    \n",
        " - If $y \\simeq H(x)$, cost is near 0.\n",
        " - If $y \\neq H(x)$, cost is high.\n",
        "<br>\n",
        "\n",
        "H(x): 어떤 Sample이 1일 확률\n",
        "</br></br>\n",
        "\n",
        "Sigmoid 함수중 하나로, sigmoid 곡선을 가진 함수. Sigmoid와 마찬가지로 모든 점에서 음이 아닌 미분 값을 가짐.   \n",
        "(1과 0 사이의 값을 가짐.)           \n",
        "</br>\n",
        "\n",
        "**➕) sigmoid 함수 종류**   \n",
        "- tanh 함수\n",
        "- logistic 함수   \n",
        "\n",
        "등   \n",
        "\n",
        "### ⚡**Cost**\n",
        "$$ cost(W) = -\\frac{1}{m} \\sum y \\log\\left(H(x)\\right) + (1-y) \\left( \\log(1-H(x) \\right) $$\n",
        "<br>\n",
        "\n",
        "### ⚡**Gradient Descent를 이용한 가중치 Update**\n",
        "$$ W := W - \\alpha \\frac{\\partial}{\\partial W} cost(W) = W - \\alpha ∇W$$\n",
        " - $\\alpha$: Learning rate"
      ],
      "metadata": {
        "id": "E6qGKgSzOMqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "njf4pSJqXlPR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q2iXUIAat0Dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf7560fd-a14c-4031-b4d5-9c7a9f44df50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78dfd08861b0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#for reproducibility\n",
        "torch.manual_seed(1) # Set the seed for generating random numbers. Return a torch.Generator object\n",
        "                     # Seed: 동일한 세트의 난수. 약간 원인? 뿌리? 느낌으로 기억하자\n",
        "                     # Random seed를 고정하기 위함! 안 그러면 값이 달라져요\n",
        "                     # 1은 시드 번호"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#강의를 듣는 시간, 코딩을 하는 시간이 주어졌을 때, 해당 코스를 통과하는지 낙제하는지를 나타내는 dataset.\n",
        "x_data = [[1, 2],[2, 3],[3, 1],[4, 3],[5, 3],[6, 2]] #|x_data| = (6, 2)\n",
        "y_data = [[0], [0], [0], [1], [1], [1]] #|y_data| = (6, 1)"
      ],
      "metadata": {
        "id": "F5BLiYwisQoz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#받아온 data를 torch로 바꿔준다.\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)"
      ],
      "metadata": {
        "id": "aFSAZGhPcGvT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOnyu4nHcWHL",
        "outputId": "063ed0bc-5ca9-4376-8193-165bf0230fc8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 2])\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing the Hypothesis\n",
        "bias도 고려해 봅시다.\n",
        "$$ H(X) =  \\frac{1}{1+e^{-XW}}$$\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;⬇\n",
        "$$ H(X) =  \\frac{1}{1+e^{-(xw + b)}}$$\n",
        "\n",
        "파이토치는 지수함수를 닮은 function인 torch.exp()를 지원합니다."
      ],
      "metadata": {
        "id": "XfIfK4kkcgI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('e^1 equeals: ', torch.exp(torch.FloatTensor([1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0FMSUE4ccXb",
        "outputId": "2252d692-5ffd-41c0-bf64-0ba47806a3ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e^1 equeals:  tensor([2.7183])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " torch.exp()를 Hypothesis에 써 보아요"
      ],
      "metadata": {
        "id": "zR9PC2xQe7iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros((2, 1), requires_grad = True)\n",
        "b= torch.zeros(1, requires_grad=True)\n",
        "\n",
        "#hypothesis = 1 / (1 + torch.exp(x_train.matmul(W) + b))\n",
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "\n",
        "print(hypothesis)\n",
        "print(hypothesis.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz1R-jH4e4aC",
        "outputId": "4274fc2a-13a6-4ad7-bc2f-b102cf1739cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
            "torch.Size([6, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing the Cost Function (Low-level)"
      ],
      "metadata": {
        "id": "g4-xmzCgkEaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# element 하나일 때(즉, 스칼라일 때)\n",
        "# -(y_train[0] * torch.log(hypothesis[0]))+(1-y_train[0])*(torch.log(1-hypothesis[0]))\n",
        "\n",
        "#vector 계산\n",
        "losses = - (y_train * torch.log(hypothesis))+(1-y_train)*(torch.log(1-hypothesis))\n",
        "\n",
        "print(losses)"
      ],
      "metadata": {
        "id": "vsgCnGoakPGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b272f68-2b2a-42a6-cc80-cca3a79b26c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6931],\n",
            "        [-0.6931],\n",
            "        [-0.6931],\n",
            "        [ 0.6931],\n",
            "        [ 0.6931],\n",
            "        [ 0.6931]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost = losses.mean()\n",
        "print(cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps07v-uTM3Ld",
        "outputId": "7f5f2bd0-d58c-428e-ff1f-e220eb14ff29"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Cross Entropy Loss\n",
        "위에서 적은 cost 구하는 공식이 바로바로 Binary Cross Entropy 입니당.\n",
        "학습을 통해 얻은 확률 분포와, 예측 분포간의 차를 측정하는 함수.   \n",
        "Cross Entropy와 달리 하나의 확률만 저장함.   \n",
        "예로,   \n",
        "동전 던지기에서 P(앞면) = 0.7로 측정되었다면, 뒷면이 나올 확률을 0.3으로 가정함.   \n",
        "Cross Entropy는 앞면 뒷면 확률 다 저장!"
      ],
      "metadata": {
        "id": "x4x8_UVIN4PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cost 구하는 코드를 아래와 같이 간단히 할 수 있다.\n",
        "F.binary_cross_entropy(hypothesis, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uIjQsE3QCXj",
        "outputId": "05068708-ff21-4140-ba63-3ed3b7e86ecb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Whole Training Procedure"
      ],
      "metadata": {
        "id": "n-_qAVsdQmfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = [[1, 2],[2, 3],[3, 1],[4, 3],[5, 3],[6, 2]] #|x_data| = (6, 2)\n",
        "y_data = [[0], [0], [0], [1], [1], [1]] #|y_data| = (6, 1)\n",
        "\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "W =  torch.zeros((2, 1), requires_grad = True)\n",
        "b = torch.zeros(1, requires_grad = True)\n",
        "\n",
        "optimizer = optim.SGD([W,b], lr=0.1)\n",
        "\n",
        "nb_epoches = 1200\n",
        "\n",
        "for epoch in range(1, nb_epoches+1):\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W)+b)\n",
        "\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} cost={:.6f}'.format(epoch, nb_epoches, cost.item()))\n",
        "        print('H(x): ', hypothesis.squeeze(dim=1).detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0drxieUIQZu7",
        "outputId": "db1b093c-c81a-4b77-9597-1995ac4b4717"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  100/1200 cost=0.415135\n",
            "H(x):  tensor([0.2175, 0.2645, 0.6875, 0.6292, 0.7866, 0.9307])\n",
            "Epoch  200/1200 cost=0.350068\n",
            "H(x):  tensor([0.1472, 0.2205, 0.6389, 0.6497, 0.8261, 0.9500])\n",
            "Epoch  300/1200 cost=0.301727\n",
            "H(x):  tensor([0.1128, 0.2077, 0.5762, 0.6734, 0.8525, 0.9566])\n",
            "Epoch  400/1200 cost=0.263868\n",
            "H(x):  tensor([0.0897, 0.2000, 0.5171, 0.6954, 0.8734, 0.9613])\n",
            "Epoch  500/1200 cost=0.233787\n",
            "H(x):  tensor([0.0725, 0.1928, 0.4655, 0.7149, 0.8904, 0.9654])\n",
            "Epoch  600/1200 cost=0.209531\n",
            "H(x):  tensor([0.0594, 0.1855, 0.4214, 0.7321, 0.9044, 0.9692])\n",
            "Epoch  700/1200 cost=0.189676\n",
            "H(x):  tensor([0.0493, 0.1782, 0.3839, 0.7472, 0.9161, 0.9726])\n",
            "Epoch  800/1200 cost=0.173186\n",
            "H(x):  tensor([0.0413, 0.1711, 0.3520, 0.7606, 0.9257, 0.9756])\n",
            "Epoch  900/1200 cost=0.159307\n",
            "H(x):  tensor([0.0350, 0.1642, 0.3245, 0.7725, 0.9339, 0.9783])\n",
            "Epoch 1000/1200 cost=0.147484\n",
            "H(x):  tensor([0.0299, 0.1577, 0.3008, 0.7832, 0.9407, 0.9806])\n",
            "Epoch 1100/1200 cost=0.137302\n",
            "H(x):  tensor([0.0258, 0.1515, 0.2802, 0.7929, 0.9466, 0.9825])\n",
            "Epoch 1200/1200 cost=0.128448\n",
            "H(x):  tensor([0.0224, 0.1457, 0.2621, 0.8017, 0.9516, 0.9843])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#소수로 나오는 hypothesis를 binary하게 0과 1로 다음과 같이 나타낼 수 있다\n",
        "prediction = hypothesis.float() >= torch.FloatTensor([0.5]) #ByteTensor를 형변환\n",
        "print(prediction[:5].type(torch.uint8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjq6u_VRWvaP",
        "outputId": "12b1693d-5014-4578-80cc-654199cedae0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1]], dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이제 y_train과 예측 값을 비교해 보자\n",
        "print(prediction[:5].type(torch.uint8))\n",
        "print(y_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiUrPfojYd5G",
        "outputId": "c7e5b4cd-4b88-44e6-e2fc-513dbd6bdc36"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1]], dtype=torch.uint8)\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction과 값이 같으면 1을 출력.\n",
        "correct_prediction = prediction.float() == y_train\n",
        "print(correct_prediction[:5].type(torch.uint8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv4rsnsRZTA5",
        "outputId": "4dac5b76-9d5b-4d85-cba2-c356a4f53efa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1]], dtype=torch.uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델을 class로 정의해봐요\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(2,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))\n",
        "\n",
        "x_data = [[1, 2],[2, 3],[3, 1],[4, 3],[5, 3],[6, 2]] #|x_data| = (6, 2)\n",
        "y_data = [[0], [0], [0], [1], [1], [1]] #|y_data| = (6, 1)\n",
        "\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "model = BinaryClassifier()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "nb_epoches = 1200\n",
        "for epoch in range(1, nb_epoches+1):\n",
        "    hypothesis = model(x_train)\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch%100 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "        correct_prediction = prediction.float() == y_train\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
        "        print('Epoch: {:4}/{} Cost: {:.6f}, Accuracy: {:2.2f}%'.format(epoch, nb_epoches, cost.item(), accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dZ3PBbSaGVM",
        "outputId": "1f6840bb-8ba7-4bdb-858e-a8a3769a6497"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  100/1200 Cost: 0.434244, Accuracy: 83.33%\n",
            "Epoch:  200/1200 Cost: 0.366090, Accuracy: 83.33%\n",
            "Epoch:  300/1200 Cost: 0.314276, Accuracy: 83.33%\n",
            "Epoch:  400/1200 Cost: 0.273754, Accuracy: 83.33%\n",
            "Epoch:  500/1200 Cost: 0.241682, Accuracy: 100.00%\n",
            "Epoch:  600/1200 Cost: 0.215933, Accuracy: 100.00%\n",
            "Epoch:  700/1200 Cost: 0.194945, Accuracy: 100.00%\n",
            "Epoch:  800/1200 Cost: 0.177584, Accuracy: 100.00%\n",
            "Epoch:  900/1200 Cost: 0.163026, Accuracy: 100.00%\n",
            "Epoch: 1000/1200 Cost: 0.150666, Accuracy: 100.00%\n",
            "Epoch: 1100/1200 Cost: 0.140053, Accuracy: 100.00%\n",
            "Epoch: 1200/1200 Cost: 0.130848, Accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ]
}