{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **실습 목표**\n",
        "**하이퍼파라미터**는 딥러닝 모델 성능에 큰 영향을 미치기 때문에, 적절한 값을 찾는 것이 중요하다.   \n",
        "**Ray**는 이런 **하이퍼파라미터의 최적값을 효율적으로 찾아내기 위한 도구**로, 병렬 연산 및 다양한 최적화 전략을 제공한다. 이를 통해 학습 시간을 단축시키고 모델의 성능을 최적화 할 수 있다.     \n",
        "CIFAR-10 데이터셋을 활용한 이미지 분류 작업에 Ray를 PyTorch와 연동하여 학습시켜보자."
      ],
      "metadata": {
        "id": "J2d5yj5Rr7DF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **모델이 성능이 안 나올 경우**\n",
        "1. 모델을 바꿔보기\n",
        "    - 사실상 가장 많은 영향을 미치지만, 이미 좋은 모델이 많이 나와있음.\n",
        "2. Data 바꿔보기(데이터를 추가하거나, 기존 data에 오류가 있는지 확인)\n",
        "    - 가장 좋은 성능을 냄.\n",
        "    - Data는 많으면 많을 수록 좋음\n",
        "3. Hyperparameter Tunning\n",
        "    - 그렇게 영향이 크진 않음.\n",
        "    - 마지막의 마지막 방법인 느낌\n",
        "    - 중요성은 낮아졌지만 그래도 함."
      ],
      "metadata": {
        "id": "O-x9IhrfdmIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**❓퀴즈**     \n",
        "### **Hyperparameter**\n",
        "- **🖊 정답:** 모델 스스로 학습하지 않는 값\n",
        "    - 사람이 지정해줘야 함\n",
        "    - learning rate, 모델의 크기, optimizer 등\n",
        "    "
      ],
      "metadata": {
        "id": "p1_IJsRWeWia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Grid Layout & Random Layout**\n",
        "가장 기본적인 방법. 최근에는 베이지안 기반 기법들이 주도하고 있음.    \n",
        "<br>\n",
        "\n",
        "**❓퀴즈**     \n",
        "#### **Grid Layout**\n",
        "- 일정한 범위를 정해서 값을 자름\n",
        "- **🖊 정답:** 하이퍼 파라미터의 가능한 모든 조합을 시험하여 최적의 조합을 찾는 방법\n",
        "- 하나를 차례대로 골라서 학습 수행, 가장 좋은 성능을 내는 것을 찾음.\n",
        "- lr는 로그를 취해서 사용\n",
        "\n",
        "#### **Random Layout**\n",
        "랜덤하게 값을 찾아 학습을 수행, 그 중 가장 잘 나온 값을 사용\n"
      ],
      "metadata": {
        "id": "351RHWUme6JA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ray**\n",
        "- Hyperparameter tunning의 대표적인 도구\n",
        "- multi node multi processing 지원 모듈\n",
        "- ML/DL의 병렬 처리를 위해 개발\n",
        "- Hyperparameter Search를 위한 다양한 모듈 제공\n",
        "<br><br>\n",
        "\n",
        "**❓퀴즈:** Ray에 관한 설명 중 가장 올바르지 않은 것은?       \n",
        "**🖊 정답:** Hyperparameter에만 특화되어있다."
      ],
      "metadata": {
        "id": "XfJxxwEEfzSm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C_Q9oeXCGIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d985a3-0b71-441c-99f6-d52f22c6d109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ray in /usr/local/lib/python3.10/dist-packages (2.24.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.14.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.31.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ray"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ray는 내부적으로 tensorboardX라는 모듈을 사용함\n",
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "D2fPvAX2CLA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "112c46ee-e176-40eb-8d86-7cf3ad1a3df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "fOcxEv6zCP5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac2c388-487a-4d03-ff14-aafa1bcab03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.5.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 데이터 로딩 및 전처리**"
      ],
      "metadata": {
        "id": "FRhkhFIyCWS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ray\n",
        "import wandb\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from functools import partial\n",
        "from torch.utils.data import random_split\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.search.bayesopt import BayesOptSearch\n",
        "from ray.tune.search.hyperopt import HyperOptSearch"
      ],
      "metadata": {
        "id": "nFB-4-5eCTfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir='./data'):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    # CIFAR10 데이터셋 로드\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform\n",
        "    )\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=False, download=True, transform=transform\n",
        "    )\n",
        "\n",
        "    return trainset, testset"
      ],
      "metadata": {
        "id": "iGc-tGYDCadU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 신경망 모델 정의**"
      ],
      "metadata": {
        "id": "L2zxIbnIDRou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    # 모델 초기화\n",
        "    # l1, l2는 여기서는 마지막 layer들의 크기에 관련된 파라미터\n",
        "    def __init__(self, l1=120, l2=84):\n",
        "        super(Net, self).__init__()\n",
        "        # 컨볼루션 레이어와 풀링 레이어\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
        "        self.fc2 = nn.Linear(l1, l2)\n",
        "        self.fc3 = nn.Linear(l2, 10)\n",
        "\n",
        "    # 순전파 정의\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "bzaOXIutDXR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **모델 학습**"
      ],
      "metadata": {
        "id": "Zd4JshMIGwCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 과정의 처음부터 끝까지 하나의 함수에 정의되어 있어야, Ray가 불러올 수 있다\n",
        "def train_cifar(config, data_dir=None):\n",
        "    # 모델 초기화\n",
        "    net = Net(config[\"l1\"], config[\"l2\"])\n",
        "\n",
        "    # 사용 가능한 장치 확인 (GPU 또는 CPU)\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)  # 멀티 GPU 사용 시 데이터 병렬 처리\n",
        "    net.to(device)  # 모델을 해당 장치로 이동\n",
        "\n",
        "    # 손실 함수 정의: 교차 엔트로피 손실 사용\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # 최적화 알고리즘 정의: SGD 사용\n",
        "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
        "\n",
        "    # 체크포인트에서 모델 및 최적화 상태 로드 (있을 경우)\n",
        "    checkpoint = ray.train.get_checkpoint()\n",
        "    if checkpoint:\n",
        "        model_state, optimizer_state = torch.load(checkpoint.path)\n",
        "        net.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "    # 데이터 로드 및 학습/검증 데이터 분할\n",
        "    trainset, testset = load_data(data_dir)\n",
        "    test_abs = int(len(trainset) * 0.8)\n",
        "    train_subset, val_subset = random_split(\n",
        "        trainset, [test_abs, len(trainset) - test_abs])\n",
        "\n",
        "    # 데이터 로더 설정\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=8)\n",
        "    valloader = torch.utils.data.DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=8)\n",
        "\n",
        "    # wandb를 사용하여 학습 과정 모니터링\n",
        "    wandb.init(project='torch-turn', entity='nayoungpark')\n",
        "    wandb.watch(net)\n",
        "\n",
        "    # 학습 시작\n",
        "    for epoch in range(10):  # 전체 데이터셋에 대해 10번 반복\n",
        "        running_loss = 0.0\n",
        "        epoch_steps = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # 입력 데이터 및 레이블 로드\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 손실 값 누적\n",
        "            running_loss += loss.item()\n",
        "            epoch_steps += 1\n",
        "\n",
        "            # 2000 미니 배치마다 손실 출력\n",
        "            if i % 2000 == 1999:\n",
        "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
        "                                                running_loss / epoch_steps))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # 검증 데이터에 대한 손실 계산\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(valloader, 0):\n",
        "            with torch.no_grad():\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.cpu().numpy()\n",
        "                val_steps += 1\n",
        "\n",
        "        # wandb에 학습 및 검증 손실 로깅\n",
        "        wandb.log({\"val_loss\": val_loss})\n",
        "        wandb.log({\"loss\": loss})\n",
        "\n",
        "        # 체크포인트 저장\n",
        "        # 이 부분은 버전 이슈로 인해 강의와 다를 수 있습니다.\n",
        "        checkpoint = ray.train.get_checkpoint()\n",
        "        path = checkpoint.save_path(\"checkpoint\")\n",
        "        torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "        # Ray Tune에 손실 및 정확도 보고\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
        "\n",
        "    print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "UbRXqPCyGykg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 모델 성능 평가**"
      ],
      "metadata": {
        "id": "2Dx6nom0lYjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(net, device='cpu'):\n",
        "    trainset, testset = load_data()\n",
        "\n",
        "    # 테스트 데이터 로더 설정\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset,\n",
        "        batch_size=4,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    # 정확하게 분류된 이미지 수 초기화\n",
        "    correct = 0\n",
        "\n",
        "    # 전체 이미지 수 초기화\n",
        "    total = 0\n",
        "\n",
        "    # 테스트 중에는 역전파가 필요 없으므로 비활성화\n",
        "    with torch.no_grad():\n",
        "        for data in testloader: # 배치 단위로 데이터 가져오기\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            # 가장 높은 확률을 가진 클래스 선택\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            # 전체 이미지 수 업데이트\n",
        "            total += labels.size(0) # labels의 첫번째 차원 반환. 배치 크기\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return correct/total"
      ],
      "metadata": {
        "id": "uyAuIgXJlbTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. 메인 실행**"
      ],
      "metadata": {
        "id": "yFp3OJCsm1rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
        "    # 데이터 디렉토리 절대 경로 설정\n",
        "    data_dir = os.path.abspath(\"./data\")\n",
        "\n",
        "    # 데이터 로드 함수 호출\n",
        "    load_data(data_dir)\n",
        "\n",
        "    # 하이퍼파라미터 설정\n",
        "    config = {# config에 search space 지정\n",
        "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
        "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
        "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
        "    }\n",
        "\n",
        "    # 스케줄러 설정 (ASHA 스케줄러 사용)\n",
        "    # 베이시안 optimization같은 알고리즘을 지정해줄 수 있다.\n",
        "    scheduler = ASHAScheduler( # 알고리즘 실행 중간에 의미없다고 생각하는 loss값이 잘 안나오는 metric들을 잘라내는 알고리즘.\n",
        "                               # 전체를 가지고 튜닝을 하면 시간이 오래걸리고 안 쓰는 결과들이 나온다.\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "\n",
        "    # 리포터 설정\n",
        "    reporter = CLIReporter(# Command line 출력 방식 지정\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "\n",
        "    # Ray Tune을 사용하여 학습 실행\n",
        "    result = tune.run( # 병렬 처리 양식\n",
        "        partial(train_cifar, data_dir=data_dir), # partial: 데이터를 쪼개는 함수\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter) # 여러개의 GPU에 뿌려져서 학습 진\n",
        "\n",
        "    # 최적의 트라이얼 결과 가져오기\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\n",
        "    print(\"Best trial final validation loss: {}\".format(\n",
        "        best_trial.last_result[\"loss\"]))\n",
        "    print(\"Best trial final validation accuracy: {}\".format(\n",
        "        best_trial.last_result[\"accuracy\"]))\n",
        "\n",
        "    # 최적의 트라이얼로 모델 초기화\n",
        "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if gpus_per_trial > 1:\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\n",
        "    best_trained_model.to(device)\n",
        "\n",
        "    # 최적의 트라이얼 체크포인트 로드\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\n",
        "        best_checkpoint_dir, \"checkpoint\"))\n",
        "    best_trained_model.load_state_dict(model_state)\n",
        "\n",
        "    # 테스트 데이터셋에서 정확도 계산\n",
        "    test_acc = test_accuracy(best_trained_model, device)\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # WandB 로그인 및 메인 함수 호출\n",
        "    wandb.login(key=\"\")\n",
        "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tCL8KsHHm5EN",
        "outputId": "b30034ed-4b3d-4383-8ad3-923a3fc63969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhcc9876\u001b[0m (\u001b[33mnayoungpark\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-17 02:55:07,651\tINFO worker.py:1753 -- Started a local Ray instance.\n",
            "2024-06-17 02:55:09,539\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
            "2024-06-17 02:55:10,369\tWARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     train_cifar_2024-06-17_02-55-09   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        AsyncHyperBandScheduler           |\n",
            "| Number of trials                 10                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/train_cifar_2024-06-17_02-55-09\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts`\n",
            "\n",
            "Trial status: 10 PENDING\n",
            "Current time: 2024-06-17 02:55:11. Total running time: 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00000   PENDING    0.0468533               16 |\n",
            "| train_cifar_0289e_00001   PENDING    0.0407774                8 |\n",
            "| train_cifar_0289e_00002   PENDING    0.0111418                2 |\n",
            "| train_cifar_0289e_00003   PENDING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "+-----------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_0289e_00000 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_0289e_00000 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    16 |\n",
            "| l1                                            16 |\n",
            "| l2                                            32 |\n",
            "| lr                                       0.04685 |\n",
            "+--------------------------------------------------+\n",
            "\u001b[36m(func pid=5938)\u001b[0m Files already downloaded and verified\n",
            "\u001b[36m(func pid=5938)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(func pid=5938)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=5938)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "\u001b[36m(func pid=5938)\u001b[0m wandb: Currently logged in as: hcc9876 (nayoungpark). Use `wandb login --relogin` to force relogin\n",
            "\u001b[36m(func pid=5938)\u001b[0m wandb: Tracking run with wandb version 0.17.1\n",
            "\u001b[36m(func pid=5938)\u001b[0m wandb: Run data is saved locally in /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/working_dirs/train_cifar_0289e_00000_0_batch_size=16,lr=0.0469_2024-06-17_02-55-10/wandb/run-20240617_025522-ka506r1c\n",
            "\u001b[36m(func pid=5938)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
            "\u001b[36m(func pid=5938)\u001b[0m wandb: Syncing run eager-jazz-29\n",
            "\u001b[36m(func pid=5938)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/nayoungpark/torch-turn\n",
            "\u001b[36m(func pid=5938)\u001b[0m wandb: 🚀 View run at https://wandb.ai/nayoungpark/torch-turn/runs/ka506r1c\n",
            "\u001b[36m(func pid=5938)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=5938)\u001b[0m   warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-06-17 02:55:42. Total running time: 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00000   RUNNING    0.0468533               16 |\n",
            "| train_cifar_0289e_00001   PENDING    0.0407774                8 |\n",
            "| train_cifar_0289e_00002   PENDING    0.0111418                2 |\n",
            "| train_cifar_0289e_00003   PENDING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=5938)\u001b[0m [1,  2000] loss: 2.240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-17 02:55:54,780\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cifar_0289e_00000\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2613, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 861, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=5938, ip=172.28.0.12, actor_id=ec66c376341c83d5f8945fe901000000, repr=func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 98, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-7-fbecd79468fb>\", line 98, in train_cifar\n",
            "AttributeError: 'NoneType' object has no attribute 'save_path'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_cifar_0289e_00000 errored after 0 iterations at 2024-06-17 02:55:54. Total running time: 44s\n",
            "Error file: /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00000_0_batch_size=16,lr=0.0469_2024-06-17_02-55-10/error.txt\n",
            "\n",
            "Trial train_cifar_0289e_00001 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_0289e_00001 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                     8 |\n",
            "| l1                                             4 |\n",
            "| l2                                           256 |\n",
            "| lr                                       0.04078 |\n",
            "+--------------------------------------------------+\n",
            "\u001b[36m(func pid=6298)\u001b[0m Files already downloaded and verified\n",
            "\u001b[36m(func pid=6298)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(func pid=6298)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=6298)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "\u001b[36m(func pid=6298)\u001b[0m wandb: Currently logged in as: hcc9876 (nayoungpark). Use `wandb login --relogin` to force relogin\n",
            "\u001b[36m(func pid=6298)\u001b[0m wandb: Tracking run with wandb version 0.17.1\n",
            "\u001b[36m(func pid=6298)\u001b[0m wandb: Run data is saved locally in /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/working_dirs/train_cifar_0289e_00001_1_batch_size=8,lr=0.0408_2024-06-17_02-55-11/wandb/run-20240617_025603-h3o2bocd\n",
            "\u001b[36m(func pid=6298)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
            "\u001b[36m(func pid=6298)\u001b[0m wandb: Syncing run solar-deluge-30\n",
            "\u001b[36m(func pid=6298)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/nayoungpark/torch-turn\n",
            "\u001b[36m(func pid=6298)\u001b[0m wandb: 🚀 View run at https://wandb.ai/nayoungpark/torch-turn/runs/h3o2bocd\n",
            "\u001b[36m(func pid=6298)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=6298)\u001b[0m   warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 1 ERROR | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-06-17 02:56:12. Total running time: 1min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00001   RUNNING    0.0407774                8 |\n",
            "| train_cifar_0289e_00002   PENDING    0.0111418                2 |\n",
            "| train_cifar_0289e_00003   PENDING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=6298)\u001b[0m [1,  2000] loss: 2.318\n",
            "\u001b[36m(func pid=6298)\u001b[0m [1,  4000] loss: 1.157\n",
            "Trial status: 1 ERROR | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-06-17 02:56:42. Total running time: 1min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00001   RUNNING    0.0407774                8 |\n",
            "| train_cifar_0289e_00002   PENDING    0.0111418                2 |\n",
            "| train_cifar_0289e_00003   PENDING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "+-----------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-17 02:56:52,639\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cifar_0289e_00001\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2613, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 861, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6298, ip=172.28.0.12, actor_id=b6105bebe875d9f73c30735401000000, repr=func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 98, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-7-fbecd79468fb>\", line 98, in train_cifar\n",
            "AttributeError: 'NoneType' object has no attribute 'save_path'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_cifar_0289e_00001 errored after 0 iterations at 2024-06-17 02:56:52. Total running time: 1min 42s\n",
            "Error file: /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00001_1_batch_size=8,lr=0.0408_2024-06-17_02-55-11/error.txt\n",
            "\n",
            "Trial train_cifar_0289e_00002 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_0289e_00002 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                     2 |\n",
            "| l1                                             8 |\n",
            "| l2                                             4 |\n",
            "| lr                                       0.01114 |\n",
            "+--------------------------------------------------+\n",
            "\u001b[36m(func pid=6719)\u001b[0m Files already downloaded and verified\n",
            "\u001b[36m(func pid=6719)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(func pid=6719)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=6719)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "\u001b[36m(func pid=6719)\u001b[0m wandb: Currently logged in as: hcc9876 (nayoungpark). Use `wandb login --relogin` to force relogin\n",
            "\u001b[36m(func pid=6719)\u001b[0m wandb: Tracking run with wandb version 0.17.1\n",
            "\u001b[36m(func pid=6719)\u001b[0m wandb: Run data is saved locally in /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/working_dirs/train_cifar_0289e_00002_2_batch_size=2,lr=0.0111_2024-06-17_02-55-11/wandb/run-20240617_025702-uibxgaur\n",
            "\u001b[36m(func pid=6719)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
            "\u001b[36m(func pid=6719)\u001b[0m wandb: Syncing run fearless-universe-31\n",
            "\u001b[36m(func pid=6719)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/nayoungpark/torch-turn\n",
            "\u001b[36m(func pid=6719)\u001b[0m wandb: 🚀 View run at https://wandb.ai/nayoungpark/torch-turn/runs/uibxgaur\n",
            "\u001b[36m(func pid=6719)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=6719)\u001b[0m   warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 2 ERROR | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-06-17 02:57:12. Total running time: 2min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00002   RUNNING    0.0111418                2 |\n",
            "| train_cifar_0289e_00003   PENDING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1,  2000] loss: 2.314\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1,  4000] loss: 1.158\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1,  6000] loss: 0.772\n",
            "Trial status: 2 ERROR | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-06-17 02:57:42. Total running time: 2min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00002   RUNNING    0.0111418                2 |\n",
            "| train_cifar_0289e_00003   PENDING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1,  8000] loss: 0.579\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1, 10000] loss: 0.463\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1, 12000] loss: 0.386\n",
            "Trial status: 2 ERROR | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-06-17 02:58:12. Total running time: 3min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00002   RUNNING    0.0111418                2 |\n",
            "| train_cifar_0289e_00003   PENDING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1, 14000] loss: 0.331\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1, 16000] loss: 0.289\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1, 18000] loss: 0.257\n",
            "Trial status: 2 ERROR | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-06-17 02:58:42. Total running time: 3min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00002   RUNNING    0.0111418                2 |\n",
            "| train_cifar_0289e_00003   PENDING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=6719)\u001b[0m [1, 20000] loss: 0.232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-17 02:59:04,702\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cifar_0289e_00002\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2613, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 861, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=6719, ip=172.28.0.12, actor_id=348cfe425f6cd930a679e42601000000, repr=func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 98, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-7-fbecd79468fb>\", line 98, in train_cifar\n",
            "AttributeError: 'NoneType' object has no attribute 'save_path'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_cifar_0289e_00002 errored after 0 iterations at 2024-06-17 02:59:04. Total running time: 3min 54s\n",
            "Error file: /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00002_2_batch_size=2,lr=0.0111_2024-06-17_02-55-11/error.txt\n",
            "\n",
            "Trial train_cifar_0289e_00003 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_0289e_00003 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                     4 |\n",
            "| l1                                           128 |\n",
            "| l2                                            32 |\n",
            "| lr                                       0.00022 |\n",
            "+--------------------------------------------------+\n",
            "\u001b[36m(func pid=7456)\u001b[0m Files already downloaded and verified\n",
            "\n",
            "Trial status: 3 ERROR | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-06-17 02:59:12. Total running time: 4min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00003   RUNNING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "| train_cifar_0289e_00002   ERROR      0.0111418                2 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=7456)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(func pid=7456)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=7456)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "\u001b[36m(func pid=7456)\u001b[0m wandb: Currently logged in as: hcc9876 (nayoungpark). Use `wandb login --relogin` to force relogin\n",
            "\u001b[36m(func pid=7456)\u001b[0m wandb: Tracking run with wandb version 0.17.1\n",
            "\u001b[36m(func pid=7456)\u001b[0m wandb: Run data is saved locally in /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/working_dirs/train_cifar_0289e_00003_3_batch_size=4,lr=0.0002_2024-06-17_02-55-11/wandb/run-20240617_025914-9gdc6qwn\n",
            "\u001b[36m(func pid=7456)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
            "\u001b[36m(func pid=7456)\u001b[0m wandb: Syncing run wild-valley-32\n",
            "\u001b[36m(func pid=7456)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/nayoungpark/torch-turn\n",
            "\u001b[36m(func pid=7456)\u001b[0m wandb: 🚀 View run at https://wandb.ai/nayoungpark/torch-turn/runs/9gdc6qwn\n",
            "\u001b[36m(func pid=7456)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=7456)\u001b[0m   warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(func pid=7456)\u001b[0m [1,  2000] loss: 2.303\n",
            "\u001b[36m(func pid=7456)\u001b[0m [1,  4000] loss: 1.148\n",
            "Trial status: 3 ERROR | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-06-17 02:59:42. Total running time: 4min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00003   RUNNING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "| train_cifar_0289e_00002   ERROR      0.0111418                2 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=7456)\u001b[0m [1,  6000] loss: 0.750\n",
            "\u001b[36m(func pid=7456)\u001b[0m [1,  8000] loss: 0.518\n",
            "Trial status: 3 ERROR | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-06-17 03:00:12. Total running time: 5min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00003   RUNNING    0.000215367              4 |\n",
            "| train_cifar_0289e_00004   PENDING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "| train_cifar_0289e_00002   ERROR      0.0111418                2 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=7456)\u001b[0m [1, 10000] loss: 0.391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-17 03:00:29,017\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cifar_0289e_00003\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2613, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 861, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=7456, ip=172.28.0.12, actor_id=a5b8ae8542adccc88f0949c901000000, repr=func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 98, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-7-fbecd79468fb>\", line 98, in train_cifar\n",
            "AttributeError: 'NoneType' object has no attribute 'save_path'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_cifar_0289e_00003 errored after 0 iterations at 2024-06-17 03:00:29. Total running time: 5min 18s\n",
            "Error file: /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00003_3_batch_size=4,lr=0.0002_2024-06-17_02-55-11/error.txt\n",
            "\n",
            "Trial train_cifar_0289e_00004 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_0289e_00004 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                     2 |\n",
            "| l1                                            32 |\n",
            "| l2                                             8 |\n",
            "| lr                                       0.00045 |\n",
            "+--------------------------------------------------+\n",
            "\u001b[36m(func pid=7993)\u001b[0m Files already downloaded and verified\n",
            "\u001b[36m(func pid=7993)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(func pid=7993)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=7993)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "\u001b[36m(func pid=7993)\u001b[0m wandb: Currently logged in as: hcc9876 (nayoungpark). Use `wandb login --relogin` to force relogin\n",
            "\u001b[36m(func pid=7993)\u001b[0m wandb: Tracking run with wandb version 0.17.1\n",
            "\u001b[36m(func pid=7993)\u001b[0m wandb: Run data is saved locally in /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/working_dirs/train_cifar_0289e_00004_4_batch_size=2,lr=0.0005_2024-06-17_02-55-11/wandb/run-20240617_030036-5j50jzlj\n",
            "\u001b[36m(func pid=7993)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
            "\u001b[36m(func pid=7993)\u001b[0m wandb: Syncing run super-surf-33\n",
            "\u001b[36m(func pid=7993)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/nayoungpark/torch-turn\n",
            "\u001b[36m(func pid=7993)\u001b[0m wandb: 🚀 View run at https://wandb.ai/nayoungpark/torch-turn/runs/5j50jzlj\n",
            "\u001b[36m(func pid=7993)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=7993)\u001b[0m   warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 4 ERROR | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-06-17 03:00:42. Total running time: 5min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00004   RUNNING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "| train_cifar_0289e_00002   ERROR      0.0111418                2 |\n",
            "| train_cifar_0289e_00003   ERROR      0.000215367              4 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1,  2000] loss: 2.307\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1,  4000] loss: 1.148\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1,  6000] loss: 0.752\n",
            "Trial status: 4 ERROR | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-06-17 03:01:12. Total running time: 6min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00004   RUNNING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "| train_cifar_0289e_00002   ERROR      0.0111418                2 |\n",
            "| train_cifar_0289e_00003   ERROR      0.000215367              4 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1,  8000] loss: 0.539\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1, 10000] loss: 0.406\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1, 12000] loss: 0.313\n",
            "Trial status: 4 ERROR | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-06-17 03:01:42. Total running time: 6min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00004   RUNNING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "| train_cifar_0289e_00002   ERROR      0.0111418                2 |\n",
            "| train_cifar_0289e_00003   ERROR      0.000215367              4 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1, 14000] loss: 0.257\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1, 16000] loss: 0.218\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1, 18000] loss: 0.189\n",
            "Trial status: 4 ERROR | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-06-17 03:02:12. Total running time: 7min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00004   RUNNING    0.000454672              2 |\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "| train_cifar_0289e_00002   ERROR      0.0111418                2 |\n",
            "| train_cifar_0289e_00003   ERROR      0.000215367              4 |\n",
            "+-----------------------------------------------------------------+\n",
            "\u001b[36m(func pid=7993)\u001b[0m [1, 20000] loss: 0.167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-17 03:02:38,240\tERROR tune_controller.py:1331 -- Trial task failed for trial train_cifar_0289e_00004\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2613, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 861, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=7993, ip=172.28.0.12, actor_id=9f63fb699df7fe37b527e1fc01000000, repr=func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 98, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 248, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-7-fbecd79468fb>\", line 98, in train_cifar\n",
            "AttributeError: 'NoneType' object has no attribute 'save_path'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial train_cifar_0289e_00004 errored after 0 iterations at 2024-06-17 03:02:38. Total running time: 7min 27s\n",
            "Error file: /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00004_4_batch_size=2,lr=0.0005_2024-06-17_02-55-11/error.txt\n",
            "\n",
            "Trial status: 5 ERROR | 5 PENDING\n",
            "Current time: 2024-06-17 03:02:42. Total running time: 7min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00005   PENDING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "| train_cifar_0289e_00002   ERROR      0.0111418                2 |\n",
            "| train_cifar_0289e_00003   ERROR      0.000215367              4 |\n",
            "| train_cifar_0289e_00004   ERROR      0.000454672              2 |\n",
            "+-----------------------------------------------------------------+\n",
            "\n",
            "Trial train_cifar_0289e_00005 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_cifar_0289e_00005 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    16 |\n",
            "| l1                                            64 |\n",
            "| l2                                             4 |\n",
            "| lr                                       0.01266 |\n",
            "+--------------------------------------------------+\n",
            "\u001b[36m(func pid=8723)\u001b[0m Files already downloaded and verified\n",
            "\u001b[36m(func pid=8723)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(func pid=8723)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=8723)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "\u001b[36m(func pid=8723)\u001b[0m wandb: Currently logged in as: hcc9876 (nayoungpark). Use `wandb login --relogin` to force relogin\n",
            "\u001b[36m(func pid=8723)\u001b[0m wandb: Tracking run with wandb version 0.17.1\n",
            "\u001b[36m(func pid=8723)\u001b[0m wandb: Run data is saved locally in /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/working_dirs/train_cifar_0289e_00005_5_batch_size=16,lr=0.0127_2024-06-17_02-55-11/wandb/run-20240617_030246-7i3peumu\n",
            "\u001b[36m(func pid=8723)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
            "\u001b[36m(func pid=8723)\u001b[0m wandb: Syncing run spring-tree-34\n",
            "\u001b[36m(func pid=8723)\u001b[0m wandb: ⭐️ View project at https://wandb.ai/nayoungpark/torch-turn\n",
            "\u001b[36m(func pid=8723)\u001b[0m wandb: 🚀 View run at https://wandb.ai/nayoungpark/torch-turn/runs/7i3peumu\n",
            "\u001b[36m(func pid=8723)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[36m(func pid=8723)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "2024-06-17 03:03:06,065\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
            "2024-06-17 03:03:06,076\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_cifar_2024-06-17_02-55-09' in 0.0083s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 5 ERROR | 1 RUNNING | 4 PENDING\n",
            "Current time: 2024-06-17 03:03:06. Total running time: 7min 55s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:T4)\n",
            "+-----------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size |\n",
            "+-----------------------------------------------------------------+\n",
            "| train_cifar_0289e_00005   RUNNING    0.0126617               16 |\n",
            "| train_cifar_0289e_00006   PENDING    0.00133331               8 |\n",
            "| train_cifar_0289e_00007   PENDING    0.000125546             16 |\n",
            "| train_cifar_0289e_00008   PENDING    0.000782675              4 |\n",
            "| train_cifar_0289e_00009   PENDING    0.0305181                4 |\n",
            "| train_cifar_0289e_00000   ERROR      0.0468533               16 |\n",
            "| train_cifar_0289e_00001   ERROR      0.0407774                8 |\n",
            "| train_cifar_0289e_00002   ERROR      0.0111418                2 |\n",
            "| train_cifar_0289e_00003   ERROR      0.000215367              4 |\n",
            "| train_cifar_0289e_00004   ERROR      0.000454672              2 |\n",
            "+-----------------------------------------------------------------+\n",
            "\n",
            "Number of errored trials: 5\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  # failures   error file                                                                                                                                                                                                      |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_cifar_0289e_00000              1   /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00000_0_batch_size=16,lr=0.0469_2024-06-17_02-55-10/error.txt |\n",
            "| train_cifar_0289e_00001              1   /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00001_1_batch_size=8,lr=0.0408_2024-06-17_02-55-11/error.txt  |\n",
            "| train_cifar_0289e_00002              1   /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00002_2_batch_size=2,lr=0.0111_2024-06-17_02-55-11/error.txt  |\n",
            "| train_cifar_0289e_00003              1   /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00003_3_batch_size=4,lr=0.0002_2024-06-17_02-55-11/error.txt  |\n",
            "| train_cifar_0289e_00004              1   /tmp/ray/session_2024-06-17_02-55-02_238598_5248/artifacts/2024-06-17_02-55-09/train_cifar_2024-06-17_02-55-09/driver_artifacts/train_cifar_0289e_00004_4_batch_size=2,lr=0.0005_2024-06-17_02-55-11/error.txt  |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f5144bbd75b6>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# WandB 로그인 및 메인 함수 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c4deceb4d95d8b5448342ffd1a1441bd51ec103a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-f5144bbd75b6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Ray Tune을 사용하여 학습 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     result = tune.run(\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cifar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mresources_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mall_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0mincomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/execution/tune_controller.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1973\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;34m\"\"\"Cleanup trials and callbacks.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cleanup_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1976\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_experiment_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/execution/tune_controller.py\u001b[0m in \u001b[0;36m_cleanup_trials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0;34m\"Waiting for actor manager to clean up final state [dedup]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                 )\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_actor_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Force cleanup of remaining actors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/actor_manager.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mstart_wait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_futures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_returns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\u001b[0m in \u001b[0;36mauto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mauto_init_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2842\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2843\u001b[0m         \u001b[0mtimeout_milliseconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2844\u001b[0;31m         ready_ids, remaining_ids = worker.core_worker.wait(\n\u001b[0m\u001b[1;32m   2845\u001b[0m             \u001b[0mray_waitables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}