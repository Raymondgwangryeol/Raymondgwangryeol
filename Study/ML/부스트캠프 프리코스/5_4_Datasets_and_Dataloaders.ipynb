{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **ì‹¤ìŠµ ëª©í‘œ**\n",
        "ì ì ˆí•œ ë°ì´í„° ì „ì²˜ë¦¬ì™€ ë¡œë”© ë°©ë²•ì€ ëª¨ë¸ì˜ ì„±ëŠ¥ê³¼ í•™ìŠµ ì†ë„ì— í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤. PyTorchëŠ” ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ì €ì¥, ê´€ë¦¬í•˜ëŠ” ê°ì²´ì¸ **Dataset**, Datasetì—ì„œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ì—¬ í•™ìŠµì— íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” **DataLoader**ë¥¼ ì œê³µí•œë‹¤. ì´ ë„êµ¬ë“¤ì˜ ê¸°ë³¸ ì›ì¹™ê³¼ ì‚¬ìš© ë°©ë²•ì„ ì´í•´í•˜ê³ , ì‹¤ì œ ë°ì´í„°ì…‹ì— ì ìš©í•´ë³´ì."
      ],
      "metadata": {
        "id": "5sJKdknwxJ3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ì–´ë–»ê²Œ í•˜ë©´ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì˜ ë„£ì–´ì„œ í•™ìŠµì„ ì‹œí‚¤ëƒê°€ ì¤‘ìš”í•œ ì´ìŠˆê°€ ë¨.    \n",
        "íŒŒì´í† ì¹˜ëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì˜ ë‹¤ë£° ìˆ˜ ìˆëŠ” dataset APIë¥¼ ì œê³µí•˜ê³  ìˆìŒ."
      ],
      "metadata": {
        "id": "RN0VQf-Qax6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset í´ë˜ìŠ¤**\n",
        "- ë°ì´í„° **ì…ë ¥ í˜•íƒœ**ë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤\n",
        "- ë°ì´í„°ë¥¼ ì…ë ¥í•˜ëŠ” ë°©ì‹ì˜ í‘œì¤€í™”\n",
        "- ë°ì´í„° í˜•íƒœì— ë”°ë¼ ê° í•¨ìˆ˜ë¥¼ ë‹¤ë¥´ê²Œ ì •ì˜\n",
        "- \\_\\_init\\_\\_()\n",
        "    - ì´ˆê¸°í™”\n",
        "- \\_\\_len\\_\\_()\n",
        "    - ë°ì´í„°ì˜ ì „ì²´ ê¸¸ì´\n",
        "- \\_\\_getitem\\_\\_()\n",
        "    - indexê°’ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë°˜í™˜ë˜ëŠ” ë°ì´í„°ì˜ í˜•íƒœë¥¼ ì •ì˜(X,y)\n",
        "-ëª¨ë“  ê²ƒì„ ë°ì´í„° ìƒì„± ì‹œì ì— ì²˜ë¦¬í•  í•„ìš”ëŠ” ì—†ìŒ\n",
        "    - \\_\\_init\\_\\_()ì—ì„œ ëª¨ë“ ê±¸ ì²˜ë¦¬í•˜ì§€ ì•Šì•„ë„ ë¨. í•™ìŠµì´ í•„ìš”í•œ ì‹œì ì— í•´ ì£¼ì"
      ],
      "metadata": {
        "id": "tVl_kVNObM4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**â“í€´ì¦ˆ**   \n",
        "### **DataLoader í´ë˜ìŠ¤**\n",
        "- **ğŸ–Š ì •ë‹µ:** Dataì˜ Batchë¥¼ ìƒì„±í•´ì£¼ëŠ” í´ë˜ìŠ¤\n",
        "- í•™ìŠµ ì§ì „(GPU feed ì „)ë°ì´í„°ì˜ ë³€í™˜(Transforms)ì„ ì±…ì„\n",
        "- Tensorë¡œ ë³€í™˜, Batch ì²˜ë¦¬ê°€ ë©”ì¸ ì—…ë¬´\n",
        "- ë³‘ë ¬ì ì¸ ë°ì´í„° ì „ì²˜ë¦¬ ì½”ë“œì˜ ê³ ë¯¼ í•„ìš”\n",
        "    - ì „ì²˜ë¦¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ Dataset í´ë˜ìŠ¤ì—ì„œ ìˆ˜í–‰ë˜ê±°ë‚˜, ë³„ë„ì˜ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì´ë£¨ì–´ì§„ë‹¤."
      ],
      "metadata": {
        "id": "B6YScYrZdUrh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQJtj0bqQVi6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import requests\n",
        "import tarfile\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from skimage import io, transform\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import VisionDataset\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Custom Dataset ë³µìŠµí•˜ê¸°**"
      ],
      "metadata": {
        "id": "rMdarD9JQ2FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# íŒŒì´í† ì¹˜ì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ CustomDataset í´ë˜ìŠ¤ë¥¼ ì •ì˜\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, text, labels):\n",
        "        self.labels = labels\n",
        "        self.text = text\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx): # dataloaderì—ì„œ í˜¸ì¶œí•˜ê²Œ ë¨\n",
        "        label = self.labels[idx]\n",
        "        text = self.text[idx]\n",
        "        sample={'Text': text, 'Class': label}\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "RXRoGKjBQ1Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['Happy', 'Amazing', 'Sad', 'Unhapy', 'Glum']\n",
        "labels = ['Positive', 'Positive', 'Negative', 'Negative', 'Negative']\n",
        "\n",
        "MyDataset = CustomDataset(text, labels)"
      ],
      "metadata": {
        "id": "7YOL2NF9RrzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(MyDataset)"
      ],
      "metadata": {
        "id": "HjGIKvAvR3pJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "257347d9-0288-4650-f35a-b3c8602181bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.CustomDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>CustomDataset</b><br/>def __init__(text, labels)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\"></a>An abstract class representing a :class:`Dataset`.\n",
              "\n",
              "All datasets that represent a map from keys to data samples should subclass\n",
              "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
              "data sample for a given key. Subclasses could also optionally overwrite\n",
              ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
              ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
              "of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
              "optionally implement :meth:`__getitems__`, for speedup batched samples\n",
              "loading. This method accepts list of indices of samples of batch and returns\n",
              "list of samples.\n",
              "\n",
              ".. note::\n",
              "  :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
              "  sampler that yields integral indices.  To make it work with a map-style\n",
              "  dataset with non-integral indices/keys, a custom sampler must be provided.</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MyDataLoader = DataLoader(MyDataset, batch_size=2, shuffle=True)\n",
        "\n",
        "for dataset in MyDataLoader:\n",
        "    print(dataset)"
      ],
      "metadata": {
        "id": "H52rTiTuR6og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bb4c25-cedc-49c8-e770-f174ee70275b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Text': ['Sad', 'Unhapy'], 'Class': ['Negative', 'Negative']}\n",
            "{'Text': ['Amazing', 'Glum'], 'Class': ['Positive', 'Negative']}\n",
            "{'Text': ['Happy'], 'Class': ['Positive']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. NotMNISTë¥¼ ì´ìš©í•˜ì—¬ Custom Dataset ë§Œë“¤ê¸°**"
      ],
      "metadata": {
        "id": "pJg4PzXSSSk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# empty fileì´ë¼ê³  ë‚˜ì˜¨ë‹¤... ì„±ê³µí–ˆë‹¤ê³  ì¹˜ê³  ë“£ì\n",
        "class NotMNIST(VisionDataset):\n",
        "    resource_url = 'http://yaroslavvb.com/upload/notMNIST/notMNIST_large.tar.gz'\n",
        "\n",
        "    def __init__(self, root:str, train:bool = True,\n",
        "                 # Optional[x] = x or None\n",
        "                 # ê¸°ë³¸ê°’ì´ ì •í•´ì§€ì§€ ì•Šì€(Noneì´ í—ˆìš©ë˜ëŠ”) íŒŒë¼ë¯¸í„°ì— ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì í•©\n",
        "                 # Callable: í˜¸ì¶œ ê°€ëŠ¥í•œ ê°ì²´ë¥¼ ì˜ë¯¸.\n",
        "                 #           1. __call__ ë©”ì„œë“œê°€ ìˆëŠ” í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ê±°ë‚˜,\n",
        "                 #            2. í˜¸ì¶œ ê°€ëŠ¥í•œ ë©”ì„œë“œë‚˜ í•¨ìˆ˜.\n",
        "                 transform: Optional[Callable] = None,\n",
        "                 target_transform: Optional[Callable] = None,\n",
        "                 download: bool = False):\n",
        "        super(NotMNIST, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "\n",
        "        #_check_exists()ëŠ” Datasetì—ì„œ Object Detection data parsing íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜\n",
        "        if not self._check_exists():\n",
        "            self.download()\n",
        "\n",
        "        self.data, self.targets = self._load_data()\n",
        "\n",
        "    # datasetì˜ ì „ì²´ ê¸¸ì´ë¥¼ ë°˜í™˜\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # loadí•œ dataë¥¼ ì°¨ë¡€ì°¨ë¡€ ëŒë ¤ì¤Œ\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.data[index]\n",
        "        image = io.imread(image_name) # numpy arrayë¥¼ ì½ì–´ì˜¨ë‹¤\n",
        "        label = self.targets[index]\n",
        "\n",
        "        if self.transform: # ì´ë ‡ê²Œ êµ³ì´ ì•ˆ í•˜ê³  ë‚˜ì¤‘ì— Transforms ê°ì²´ ì¨ë„ ëœë‹¤.\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def _load_data(self): # ë°ì´í„°ë¥¼ ë°›ì•„ì„œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“ ë‹¤\n",
        "        filepath = self.image_folder\n",
        "        data = []\n",
        "        targets = []\n",
        "\n",
        "        # ê° í´ë˜ìŠ¤ ë³„ë¡œ ë°ì´í„° ë¡œë“œ\n",
        "        for target in os.listdir(filepath):\n",
        "            # abspath: ì ˆëŒ€ê²½ë¡œ êµ¬í•˜ê¸°\n",
        "            filenames = [os.path.abspath(os.path.join(filepath, target, x)) for x in os.listdir(os.path.join(filepath, target))]\n",
        "            targets.extend([target] * len(filenames))\n",
        "            data.extend(filenames)\n",
        "        # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ì™€ targetì„ ì •ì˜ í•´ì¤€ë‹¤\n",
        "        # ì´ë¯¸ì§€ íŒŒì¼ì€ í´ë”ì— ì €ì¥ë˜ì–´ ìˆê³ , ê°ê°ì˜ í´ë”ê°€ labelì´ ë˜ê¸° ë•Œë¬¸\n",
        "        return data, targets #filename = data, label = targets\n",
        "\n",
        "    # @: decorator: ì–´ë–¤ í•¨ìˆ˜ë¥¼ ê¾¸ë©°ì„œ ìƒˆ í•¨ìˆ˜ë¡œ ë§Œë“œëŠ” ê¸°ëŠ¥\n",
        "    # propertyí•¨ìˆ˜ê°€ raw_folder í•¨ìˆ˜ë¥¼ ê¾¸ë©°ì£¼ê³  ìˆëŠ” êµ¬ì¡°.\n",
        "    # raw_folder = property(raw_folder)\n",
        "    # ì¦‰, raw_folderê°€ propertyì˜ resultê°€ ë˜ëŠ” ê²ƒ.\n",
        "    # propertyë¥¼ ë¶™ì´ë©´ NotMNIST.raw_folderí•˜ë©´ raw_folderë¥¼ ì‹¤í–‰ì‹œí‚¬ ìˆ˜ ìˆìŒ.\n",
        "    # ì›ë³¸ ë°ì´í„° í´ë” ê²½ë¡œ\n",
        "    @property\n",
        "    def raw_folder(self) -> str:\n",
        "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
        "\n",
        "    # ì´ë¯¸ì§€ í´ë” ê²½ë¡œ\n",
        "    @property\n",
        "    def image_folder(self) -> str:\n",
        "        return os.path.join(self.root, 'notMNIST_large')\n",
        "\n",
        "    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜\n",
        "    def download(self) -> None:\n",
        "        os.makedirs(self.raw_folder, exist_ok=True)\n",
        "        os.makedirs(self.image_folder, exist_ok=True)\n",
        "        fname = self.resource_url.split(\"/\")[-1]\n",
        "        user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.6422.142 Safari/537.36'\n",
        "        response = requests.head(self.resource_url, headers={\"User-Agent\": user_agent})\n",
        "        filesize = int(response.headers.get(\"Content-Length\", 0))  # Use 0 if not found\n",
        "        # ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì§„í–‰ ìƒí™© í‘œì‹œ\n",
        "        with requests.get(self.resource_url, stream=True, headers={\"User-Agent\": user_agent}) as r, \\\n",
        "                open(os.path.join(self.raw_folder, fname), \"wb\") as f, \\\n",
        "                tqdm(unit=\"B\", unit_scale=True, unit_divisor=1024, total=filesize, file=sys.stdout, desc=fname) as progress:\n",
        "            for chunk in r.iter_content(chunk_size=1024):\n",
        "                datasize = f.write(chunk)\n",
        "                progress.update(datasize)\n",
        "\n",
        "            self._extract_file(os.path.join(self.raw_folder, fname), target_path=self.root)\n",
        "\n",
        "    # íŒŒì¼ ì••ì¶• í•´ì œ í•¨ìˆ˜\n",
        "    def _extract_file(self, fname, target_path) -> None:\n",
        "        tag = 'r:gz' if fname.endswith('tar.gz') else 'r:'\n",
        "        with tarfile.open(fname,tag) as tar:\n",
        "            tar.extractall(path=target_path)\n",
        "\n",
        "    # ë°ì´í„°ì…‹ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í•¨ìˆ˜\n",
        "    def _check_exists(self) -> bool:\n",
        "        return os.path.exists(self.raw_folder)"
      ],
      "metadata": {
        "id": "zsUbC-ccSb4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„°ì…‹ ìƒì„±\n",
        "dataset = NotMNIST(\"data\", download = True)"
      ],
      "metadata": {
        "id": "84_XraeAZtM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "# 8ê°œì˜ ìƒ˜í”Œ ì´ë¯¸ì§€ ì¶œë ¥\n",
        "for i in range(8):\n",
        "    sample = dataset[i]\n",
        "    # 1í–‰ 4ì—´ì˜ ì„œë¸Œí”Œë¡¯ ì¤‘ i+1ë²ˆì§¸ ìœ„ì¹˜ì— ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
        "    ax = plt.subplot(1, 4, i+1)\n",
        "    # ë ˆì´ì•„ì›ƒì„ ì¡°ì ˆí•˜ì—¬ ê·¸ë˜í”„ ê°„ì˜ ê°„ê²©ì„ ìµœì í™”\n",
        "    plt.tight_layout()\n",
        "    # ì„œë¸Œí”Œë¡¯ì˜ ì œëª© ì„¤ì •\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    # ì„œë¸Œí”Œë¡¯ ì¶• ìˆ¨ê¸°ê¸°\n",
        "    ax.axis('off')\n",
        "    plt.imshow(sample[0])\n",
        "\n",
        "    # 4ê°œì˜ ìƒ˜í”Œ ì´ë¯¸ì§€ ì¶œë ¥ í›„, ê·¸ë¦¼ì„ í™”ë©´ì— í‘œì‹œí•˜ê³  ë°˜ë³µë¬¸ì„ ì¢…ë£Œ.\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ],
      "metadata": {
        "id": "Rhjqoa6nZ2Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€í™˜(Transform) ê°ì²´ë¥¼ ìƒì„±.\n",
        "# ì—¬ëŸ¬ ì „ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©í•˜ê¸° ìœ„í•´ Composeë¥¼ ì‚¬ìš©(PyTorch transforms.Compose)\n",
        "data_transform = transforms.Compose([\n",
        "\n",
        "        # 224X224 í¬ê¸°ë¡œ ë¬´ì‘ìœ„ë¡œ ì´ë¯¸ì§€ë¥¼ ì˜ë¼ëƒ„.\n",
        "        transforms.RandomCrop(224)\n",
        "        # 0.5ì˜ í™•ë¥ ë¡œ ì´ë¯¸ì§€ë¥¼ ìˆ˜í‰ìœ¼ë¡œ ë’¤ì§‘ìŒ.\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        # ì´ë¯¸ì§€ë¥¼ í…ì„œ(Tensor) í˜•íƒœë¡œ ë³€í™˜\n",
        "        transforms.ToTensor(),\n",
        "        # ì£¼ì–´ì§„ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì •ê·œí™”.\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "# NotMNIST ë°ì´í„°ì…‹ ë¡œë“œ.(ë‹¤ìš´ë¡œë“œ X)\n",
        "dataset = NotMNIST(\"data\", download=False)"
      ],
      "metadata": {
        "id": "Mcl-2kbhllpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„°ì…‹ì„ ë°°ì¹˜ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ë¡œë“œí•˜ê¸° ìœ„í•œ DataLoader ê°ì²´ ìƒì„±.\n",
        "# ë°°ì¹˜ í¬ê¸° 128, ë°ì´í„° ì…”í”Œí•´ì„œ ë¡œë“œ\n",
        "# iterableí•œ generatorë¡œ ë§Œë“¤ì–´ ì¤€ë‹¤\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "-mrxPLkenHHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoaderì—ì„œ ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ íŠ¹ì„±(features)ì™€ labels ê°€ì ¸ì˜¤ê¸°.\n",
        "# nextëŠ” ë°˜ë³µìì˜ ë°”ë¡œ ë‹¤ìŒ í•­ëª©ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.\n",
        "train_features, train_labels = next(iter(dataset_loader))"
      ],
      "metadata": {
        "id": "4lVM52TjnmM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì²« ë²ˆì§¸ ë°°ì¹˜ íŠ¹ì„±ì˜ í˜•íƒœ(shape) ì¶œë ¥\n",
        "# 128,28,28\n",
        "train_features.shape"
      ],
      "metadata": {
        "id": "Qg0FyOSZn8it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì²« ë²ˆì§¸ ë°°ì¹˜ ë ˆì´ë¸” ì¶œë ¥\n",
        "train_labels"
      ],
      "metadata": {
        "id": "ESoRhgW9oE4_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}