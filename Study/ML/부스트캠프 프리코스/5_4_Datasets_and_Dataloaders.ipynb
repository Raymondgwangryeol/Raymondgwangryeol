{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **실습 목표**\n",
        "적절한 데이터 전처리와 로딩 방법은 모델의 성능과 학습 속도에 큰 영향을 미친다. PyTorch는 모델 학습에 필요한 데이터를 저장, 관리하는 객체인 **Dataset**, Dataset에서 배치 단위로 데이터를 로딩하여 학습에 효율적으로 사용하는 **DataLoader**를 제공한다. 이 도구들의 기본 원칙과 사용 방법을 이해하고, 실제 데이터셋에 적용해보자."
      ],
      "metadata": {
        "id": "5sJKdknwxJ3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "시간이 지날수록 어떻게 하면 대용량 데이터를 잘 넣어서 학습을 시키냐가 중요한 이슈가 됨.    \n",
        "파이토치는 대용량 데이터를 잘 다룰 수 있는 dataset API를 제공하고 있음."
      ],
      "metadata": {
        "id": "RN0VQf-Qax6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset 클래스**\n",
        "- 데이터 **입력 형태**를 정의하는 클래스\n",
        "- 데이터를 입력하는 방식의 표준화\n",
        "- 데이터 형태에 따라 각 함수를 다르게 정의\n",
        "- \\_\\_init\\_\\_()\n",
        "    - 초기화\n",
        "- \\_\\_len\\_\\_()\n",
        "    - 데이터의 전체 길이\n",
        "- \\_\\_getitem\\_\\_()\n",
        "    - index값이 주어졌을 때, 반환되는 데이터의 형태를 정의(X,y)\n",
        "-모든 것을 데이터 생성 시점에 처리할 필요는 없음\n",
        "    - \\_\\_init\\_\\_()에서 모든걸 처리하지 않아도 됨. 학습이 필요한 시점에 해 주자"
      ],
      "metadata": {
        "id": "tVl_kVNObM4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**❓퀴즈**   \n",
        "### **DataLoader 클래스**\n",
        "- **🖊 정답:** Data의 Batch를 생성해주는 클래스\n",
        "- 학습 직전(GPU feed 전)데이터의 변환(Transforms)을 책임\n",
        "- Tensor로 변환, Batch 처리가 메인 업무\n",
        "- 병렬적인 데이터 전처리 코드의 고민 필요\n",
        "    - 전처리는 일반적으로 Dataset 클래스에서 수행되거나, 별도의 전처리 파이프라인을 통해 이루어진다."
      ],
      "metadata": {
        "id": "B6YScYrZdUrh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQJtj0bqQVi6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import requests\n",
        "import tarfile\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from skimage import io, transform\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import VisionDataset\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Custom Dataset 복습하기**"
      ],
      "metadata": {
        "id": "rMdarD9JQ2FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파이토치의 Dataset 클래스를 상속받아 CustomDataset 클래스를 정의\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, text, labels):\n",
        "        self.labels = labels\n",
        "        self.text = text\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx): # dataloader에서 호출하게 됨\n",
        "        label = self.labels[idx]\n",
        "        text = self.text[idx]\n",
        "        sample={'Text': text, 'Class': label}\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "RXRoGKjBQ1Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['Happy', 'Amazing', 'Sad', 'Unhapy', 'Glum']\n",
        "labels = ['Positive', 'Positive', 'Negative', 'Negative', 'Negative']\n",
        "\n",
        "MyDataset = CustomDataset(text, labels)"
      ],
      "metadata": {
        "id": "7YOL2NF9RrzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(MyDataset)"
      ],
      "metadata": {
        "id": "HjGIKvAvR3pJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "257347d9-0288-4650-f35a-b3c8602181bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.CustomDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>CustomDataset</b><br/>def __init__(text, labels)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\"></a>An abstract class representing a :class:`Dataset`.\n",
              "\n",
              "All datasets that represent a map from keys to data samples should subclass\n",
              "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
              "data sample for a given key. Subclasses could also optionally overwrite\n",
              ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
              ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
              "of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
              "optionally implement :meth:`__getitems__`, for speedup batched samples\n",
              "loading. This method accepts list of indices of samples of batch and returns\n",
              "list of samples.\n",
              "\n",
              ".. note::\n",
              "  :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
              "  sampler that yields integral indices.  To make it work with a map-style\n",
              "  dataset with non-integral indices/keys, a custom sampler must be provided.</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MyDataLoader = DataLoader(MyDataset, batch_size=2, shuffle=True)\n",
        "\n",
        "for dataset in MyDataLoader:\n",
        "    print(dataset)"
      ],
      "metadata": {
        "id": "H52rTiTuR6og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bb4c25-cedc-49c8-e770-f174ee70275b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Text': ['Sad', 'Unhapy'], 'Class': ['Negative', 'Negative']}\n",
            "{'Text': ['Amazing', 'Glum'], 'Class': ['Positive', 'Negative']}\n",
            "{'Text': ['Happy'], 'Class': ['Positive']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. NotMNIST를 이용하여 Custom Dataset 만들기**"
      ],
      "metadata": {
        "id": "pJg4PzXSSSk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# empty file이라고 나온다... 성공했다고 치고 듣자\n",
        "class NotMNIST(VisionDataset):\n",
        "    resource_url = 'http://yaroslavvb.com/upload/notMNIST/notMNIST_large.tar.gz'\n",
        "\n",
        "    def __init__(self, root:str, train:bool = True,\n",
        "                 # Optional[x] = x or None\n",
        "                 # 기본값이 정해지지 않은(None이 허용되는) 파라미터에 사용하는 것이 적합\n",
        "                 # Callable: 호출 가능한 객체를 의미.\n",
        "                 #           1. __call__ 메서드가 있는 클래스 인스턴스거나,\n",
        "                 #            2. 호출 가능한 메서드나 함수.\n",
        "                 transform: Optional[Callable] = None,\n",
        "                 target_transform: Optional[Callable] = None,\n",
        "                 download: bool = False):\n",
        "        super(NotMNIST, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "\n",
        "        #_check_exists()는 Dataset에서 Object Detection data parsing 파일 존재 여부를 확인하는 함수\n",
        "        if not self._check_exists():\n",
        "            self.download()\n",
        "\n",
        "        self.data, self.targets = self._load_data()\n",
        "\n",
        "    # dataset의 전체 길이를 반환\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # load한 data를 차례차례 돌려줌\n",
        "    def __getitem__(self, index):\n",
        "        image_name = self.data[index]\n",
        "        image = io.imread(image_name) # numpy array를 읽어온다\n",
        "        label = self.targets[index]\n",
        "\n",
        "        if self.transform: # 이렇게 굳이 안 하고 나중에 Transforms 객체 써도 된다.\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def _load_data(self): # 데이터를 받아서 데이터 리스트를 만든다\n",
        "        filepath = self.image_folder\n",
        "        data = []\n",
        "        targets = []\n",
        "\n",
        "        # 각 클래스 별로 데이터 로드\n",
        "        for target in os.listdir(filepath):\n",
        "            # abspath: 절대경로 구하기\n",
        "            filenames = [os.path.abspath(os.path.join(filepath, target, x)) for x in os.listdir(os.path.join(filepath, target))]\n",
        "            targets.extend([target] * len(filenames))\n",
        "            data.extend(filenames)\n",
        "        # 파일 리스트와 target을 정의 해준다\n",
        "        # 이미지 파일은 폴더에 저장되어 있고, 각각의 폴더가 label이 되기 때문\n",
        "        return data, targets #filename = data, label = targets\n",
        "\n",
        "    # @: decorator: 어떤 함수를 꾸며서 새 함수로 만드는 기능\n",
        "    # property함수가 raw_folder 함수를 꾸며주고 있는 구조.\n",
        "    # raw_folder = property(raw_folder)\n",
        "    # 즉, raw_folder가 property의 result가 되는 것.\n",
        "    # property를 붙이면 NotMNIST.raw_folder하면 raw_folder를 실행시킬 수 있음.\n",
        "    # 원본 데이터 폴더 경로\n",
        "    @property\n",
        "    def raw_folder(self) -> str:\n",
        "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
        "\n",
        "    # 이미지 폴더 경로\n",
        "    @property\n",
        "    def image_folder(self) -> str:\n",
        "        return os.path.join(self.root, 'notMNIST_large')\n",
        "\n",
        "    # 데이터 다운로드 함수\n",
        "    def download(self) -> None:\n",
        "        os.makedirs(self.raw_folder, exist_ok=True)\n",
        "        os.makedirs(self.image_folder, exist_ok=True)\n",
        "        fname = self.resource_url.split(\"/\")[-1]\n",
        "        user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.6422.142 Safari/537.36'\n",
        "        response = requests.head(self.resource_url, headers={\"User-Agent\": user_agent})\n",
        "        filesize = int(response.headers.get(\"Content-Length\", 0))  # Use 0 if not found\n",
        "        # 데이터 다운로드 진행 상황 표시\n",
        "        with requests.get(self.resource_url, stream=True, headers={\"User-Agent\": user_agent}) as r, \\\n",
        "                open(os.path.join(self.raw_folder, fname), \"wb\") as f, \\\n",
        "                tqdm(unit=\"B\", unit_scale=True, unit_divisor=1024, total=filesize, file=sys.stdout, desc=fname) as progress:\n",
        "            for chunk in r.iter_content(chunk_size=1024):\n",
        "                datasize = f.write(chunk)\n",
        "                progress.update(datasize)\n",
        "\n",
        "            self._extract_file(os.path.join(self.raw_folder, fname), target_path=self.root)\n",
        "\n",
        "    # 파일 압축 해제 함수\n",
        "    def _extract_file(self, fname, target_path) -> None:\n",
        "        tag = 'r:gz' if fname.endswith('tar.gz') else 'r:'\n",
        "        with tarfile.open(fname,tag) as tar:\n",
        "            tar.extractall(path=target_path)\n",
        "\n",
        "    # 데이터셋 존재 여부 확인 함수\n",
        "    def _check_exists(self) -> bool:\n",
        "        return os.path.exists(self.raw_folder)"
      ],
      "metadata": {
        "id": "zsUbC-ccSb4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 생성\n",
        "dataset = NotMNIST(\"data\", download = True)"
      ],
      "metadata": {
        "id": "84_XraeAZtM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "# 8개의 샘플 이미지 출력\n",
        "for i in range(8):\n",
        "    sample = dataset[i]\n",
        "    # 1행 4열의 서브플롯 중 i+1번째 위치에 그래프 그리기\n",
        "    ax = plt.subplot(1, 4, i+1)\n",
        "    # 레이아웃을 조절하여 그래프 간의 간격을 최적화\n",
        "    plt.tight_layout()\n",
        "    # 서브플롯의 제목 설정\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    # 서브플롯 축 숨기기\n",
        "    ax.axis('off')\n",
        "    plt.imshow(sample[0])\n",
        "\n",
        "    # 4개의 샘플 이미지 출력 후, 그림을 화면에 표시하고 반복문을 종료.\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ],
      "metadata": {
        "id": "Rhjqoa6nZ2Nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리를 위한 변환(Transform) 객체를 생성.\n",
        "# 여러 전처리 단계를 순차적으로 적용하기 위해 Compose를 사용(PyTorch transforms.Compose)\n",
        "data_transform = transforms.Compose([\n",
        "\n",
        "        # 224X224 크기로 무작위로 이미지를 잘라냄.\n",
        "        transforms.RandomCrop(224)\n",
        "        # 0.5의 확률로 이미지를 수평으로 뒤집음.\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        # 이미지를 텐서(Tensor) 형태로 변환\n",
        "        transforms.ToTensor(),\n",
        "        # 주어진 평균과 표준편차를 사용하여 이미지를 정규화.\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "# NotMNIST 데이터셋 로드.(다운로드 X)\n",
        "dataset = NotMNIST(\"data\", download=False)"
      ],
      "metadata": {
        "id": "Mcl-2kbhllpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋을 배치 크기로 나누어 로드하기 위한 DataLoader 객체 생성.\n",
        "# 배치 크기 128, 데이터 셔플해서 로드\n",
        "# iterable한 generator로 만들어 준다\n",
        "dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "-mrxPLkenHHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader에서 첫 번째 배치의 특성(features)와 labels 가져오기.\n",
        "# next는 반복자의 바로 다음 항목을 가져오는 함수.\n",
        "train_features, train_labels = next(iter(dataset_loader))"
      ],
      "metadata": {
        "id": "4lVM52TjnmM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 배치 특성의 형태(shape) 출력\n",
        "# 128,28,28\n",
        "train_features.shape"
      ],
      "metadata": {
        "id": "Qg0FyOSZn8it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 배치 레이블 출력\n",
        "train_labels"
      ],
      "metadata": {
        "id": "ESoRhgW9oE4_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}