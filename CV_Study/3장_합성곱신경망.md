# 3장. 합성곱 신경망
강의: 세종대학교 최유경 교수님 딥러닝시스템(2023)
</br></br>
## 목차
1. 다층 퍼셉트론을 이용한 이미지 분류
2. 합성곱 신경망 구조
3. 합성곱 신경망의 기본 요소
5. 과적합
</br></br></br>

## 3-1. 다층 퍼셉트론을 이용한 이미지 분류

해당 강의에서는 MNIST 데이터셋을 사용한 이미지 분류 문제로 MLP(다층 퍼셉트론)를 설명함.      
  일단 결론은 MLP 모델의 한계(문제)가 있고,
  </br>
  
  1. 입력층      
  신경망으로 2차원 이미지(MNIST)를 다루기 위해서는 신경망이 이해할 수 있는 형태로 변환해야함.
  </br>
  
  MLP 입력층은 1차원 벡터(1,N)만 입력 받기 때문에, 2차원 행렬을 1차원 벡터로 변환해야 함. 이 과정을 이미지 벡터 변환(Image Flattering)이라 함.     
</br>

  2. 은닉층
  신경망은 하나 이상의 뉴런으로 구성된 여러개의 은닉층을 가질 수 있음.     
  이 문제에서는 노드 512개를 가진 은닉층을 두 층 만들고, 각 층마다 ReLU함수를 추가함.       
  </br>
  
  3. 출력층      
    분류 문제의 출력층 노드 수 = 분류 대상 클래스 수     
    해당 문제는 0부터 9까지 숫자 10개가 분류 대상이기 때문에 노드 10개를 갖는 Dense층(다층 퍼셉트론 신경망에서 사용되는 레이어로 입력과 출력을 모두 연결해주는 층)을 추가하면 됨.    
  </br>
  
  MLP가 가지고 있는 단점을 해결하기 위해 CNN이 나오게 됨.
  </br>
  
  #### MLP의 단점   
  1. 공간적 특징의 손실(2D → 1D). 서로 가까이 위치한 픽셀 간의 관계를 알 수 없어 정보 손실이 발생 
  2. 복잡한 신경망 학습(파라미터가 많이 생김)

### ■ CNN
 합성곱 신경망(Convolutional Neural Network)은 이미지(영상)를 다루는데 특화된 머신러닝 구조임.      
</br>
MLP는 전결합층으로 구성되어 복잡한 신경망 학습등 단점이 있지만 CNN의 노드는 이전 층의 노드 중 일부하고만 연결됨.(지역적 Locally Connected)      
</br>

## 3-2. 합성곱 신경망 구조
MLP와 CNN은 특징 학습(3단계)과 이미지 분류(4단계)과정을 함께 수행함. MLP의 경우 전결합층의 문제는 4단계인 이미지 분류 과정 보다는, 3단계인 특징 학습 단계에 있음.      
따라서, 분류는 잘 하니까 전결합층을 분류에 그대로 사용하고, 대신 특징 추출을지역적 연결을 가진 합성곱층으로 변경함.      
</br>

#### CNN의 추상적 구조
  - 입력층
  - 합성곱층(특징 추출 담당)
  - 전결합층(분류 담당)
  - 출력층
</br>
#### 특징맵?

CNN에서는 많은 층을 거쳐 점진적으로 이미지의 특징을 추출, 학습함.    
층이 깊어질수록 복잡한 형태의 패턴을 학습할 수 있음.(직선 → 도형 → 사람의 이목구비...)    
</br></br>

## 3-3. 합성곱 신경망의 기본 요소

   1. 합성곱층(Cpmvolutional Layer, CONV) → 특징 추출
   2. 풀링층(Pooling Layer, POOL)
   3. 전결합층(Fully Connected Layer, FC) → 분류
   </br>

#### 신경망 학습 과정(아래 이미지 참고)     
  CNN에서는 합성곱과 전결합층을 원하는 만큼 둘수 있음. 아래 예시는 합성곱 2개와 전결합층 1개로 이루어짐. 해당 CNN구조의 학습 과정은 아래와 같음.      
  입력 → CONV(+ReLU) → POOL → CONV(+ReLU) → POOL → FC(+SOFTMAX)    
  ReLU와 CONV, SOFTMAX와 FC는 독립적인 층이 아니고, 두 개씩 함께 층을 사용함.      
  </br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_3-12.png"></img></br>
</br>
1. 합성곱층
</br>

  합성곱이란, 두 함수를 인수로 새로운 함수를 만들어 내는 연산임. 입력 이미지와 합성곱 필터(또는 커널)를 각각 합성곱의 인수로 넣고, 합성곱 계산을 통해 새로운 이미지를 생성함.     
  </br>
  합성곱 필터를 이미지 위로 이동시키기 → 합성곱 필터 위치한 부분에 해당하는 픽셀 단위의 이미지 조각을 처리한 결과를 모으기 → 새로운 이미지인 특징맵 만듦         
  </br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_3-13.png"></img></br> 
  </br>
  커널(합성곱 필터)은 가중치가 담긴 행렬로, 입력 이미지 위를 픽셀 단위로 움직이며 연산을 수행, 픽셀값을 계산함. 계산된 픽셀값을 모아 새로운 이미지를 만들고, 다음 층으로 데이터가 전달됨.         
  필터가 위치한 입력 이미지상의 범위를 수용 영역(Receptive Field)라 함.       
  </br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_3-14.png"></img></br>
  </br>
  #### 커널 크기
  커널 크기는 합성곱 필터 크기(너비 X 높이)를 의미함. 커널 크기는 합성곱층을 만들기 위한 하이퍼파라미터 중 하나임.      
  크기가 작을수록 이미지의 세세한 부분까지 잡을 수 있고, 클수록 신경망이 복잡한 패턴을 학습할 수 있음.(하지만 연산 복잡도가 올라기 때문에 과적합 일으키기 쉬움)      
  커널은 대부분 정사각형이며, 크기는 최소 2X2, 최대 5X5임.      
  </br>
  스트라이드와 패딩은 합성곱층의 출력 모양을 결정하는 하이퍼파라미터임.
  </br>

  #### 스트라이드(Stride)
  필터가 입력 이미지 위를 한 번 이동할 때 움직이는 픽셀 수.     
  스트라이드가 1이면 입력 이미지와 거의 같은 크기의 출력 데이터가 나오고, 2로 설정하면 출력 이미지가 거의 입력 이미지의 절반크기가 됨.(거의라는 단어를 넣은 이유는 패딩 설정에 따라 출력 이미지의 크기가 달라질 수 있기 때문) 이와 같이 여러 픽셀을 건너뛰면 출력값 크기가 작아지기 때문에 3이상 스트라이드 값은 잘 사용하지 않음.(1이나 2 사용)    
  </br>

  #### 패딩(Padding)
  합성곱 연산을 거친 출력 이미지의 크기를 입력 이미지의 크기와 같게 유지하는 목적으로 쓰임.     
  제로 패딩은 이미지 둘레에 픽셀값이 0인 픽셀들을 추가적으로 덧붙이는 것을 말함.     
  </br>

  #### 합성곱 연산(다층 퍼셉트론의 **가중치** 합과 같음. )      
  입력에 가중치를 곱하고, 그 결과들을 합해서 계산. 뉴런과 가중치가 행렬처럼 배열되어 있음.         
  </br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_3-15.png"></img></br>
  </br>

  합성곱층에는 하나 또는 여러개의 합성곱 필터가 있으며, 합성곱 필터 수 만큼 특징 맵이 출력되기 때문에 필터 수가 다음 층의 깊이를 결정함.       
  </br>
  </br>

2. 풀링층
  합성곱층이 많아지다 보면 계산 복잡도가 상승하고, 파라미터도 많아짐. 이 문제를 해결하기 위해 특징 맵의 개수는 유지하면서 전달되는 파라미터 수를 감소시키는 풀링층을 사용함.(입력 크기 축소)     
  CNN구조에서는 일반적으로 합성곱층 사이에 풀링층을 끼워 넣는 경우가 많음.     
  </br>

  #### 최대 풀링(Max Pooling)   
  윈도우 크기와 스트라이드라는 하이퍼파라미터 존재. 다만 행렬에 **별도의 가중치가 없음.**        
  자신 앞의 합성곱층에서 출력된 특징 맵을 입력받아 커널을 이미지 위로 이동시키면서, 동시에 윈도우 내 픽셀 값의 최대값을 찾아 이를 출력 이미지의 픽셀 값으로 삼음.    
  </br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_3-21.png"></img></br>
  </br>

  #### 평균 풀링(Average Pooling)
  극단적으로 특징 맵 크기를 줄이는 방식. 윈도우 크기와 스트라이드를 설정하지 않고, 전체 특징 맵 픽셀 값의 평균을 구함.      
  </br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_3-23.png"></img></br>
  </br>

  #### 풀링층 사용 이유?
  풀링층을 사용하면 이미지 데이터의 중요 특징을 잃지 않고 이미지 크기를 줄일 수 있음. 즉, 특징은 유지하되 이미지의 해상도를 낮춰 규모를 줄임.     
  </br><img src="https://drek4537l1klr.cloudfront.net/elgendy/HighResolutionFigures/figure_3-25.png"></img></br>
  </br></br>

  ### ■ CNN 모델 학습 과정
  아래와 같이 크기가 28X28인 입력 이미지가 있고, 스트라이트와 패딩이 1인 합성곱층이 있다고 가정.   
  </br><img src=""></img></br>
  필터 수에 따라 출력 이미지의 깊이가 결정되는 것을 볼 수 있음.     
  </br>

  풀링층을 통과한 데이터의 출력은 입력 데이터랑 동일한 깊이를 가지지만, 크기는 줄어듦.   
  </br><img src=""></img></br>
</br>
합성곱층과 풀링층을 번갈아 배치한 뒤 학습하는 과정은 아래와 같으며, 결과가 모든 특징이 늘어선 매우 긴 막대기같은 모양이 될 때까지 학습을 반복함.   
출력 데이터의 특징이 분류를 거친 준비가 된 상태라면, 해당 데이터를 1차원 벡터로 변환시켜 전결합층에 입력(분류).     

## 3-5. 과적합
머신러닝 학습시 성능 저하의 이유 중 하나임.    
</br>
#### 과소적합(Underfitting)
  모델이 학습 데이터에 부합하지 못하는 현상. 모델이 데이터를 나타내기엔 너무 단순한 경우 발생.     
#### 과적합(Overfitting)
  모델이 학습 데이터에 지나치게 부합하는 현상.(학습 오차가 매우 적음)    
  모델의 표현력이 매우 좋아 처음 보는 데이터는 잘 예측하지 못해 일반화 성능이 떨어짐.   
</br>
### 드롭아웃(Dropout)
  과적합을 방지하기 위한 수단으로 가장 널리 사용.(강의에서 요즘에는 다른방법을 쓰는 추세라고 지나가듯이 말씀하심)    
  노드 중 일부를 무작위로 비활성화 하는 방법으로, 비활성화 노드 비율은 하이퍼파리미터로 지정함.     
  뉴런은 학습 과정을 거치며 상호 의존 관계를 구축하는데, 이 의존 관계는 각 뉴런의 영향력을 결정하며 과적합의 원인이 됨.    
  아무 노드들을 뽑아 비활성화 시키면, 영향력이 지나치게 약하거나 강한 노드가 생기는 것을 방지할 수 있음.
  학습 단계에서만 사용되며, 일반적으로 추출된 특징의 1차원 벡터 변환이 끝난 다음부터 마지막 출력층 사이에 배치함.

