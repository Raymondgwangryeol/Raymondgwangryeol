## 5장. 고급 합성곱 신경망 구조 
</br>
강의: 세종대학교 최유경교수님 딥러닝시스템 강의(2023)     
</br></br>

## 목차
1. CNN의 디자인 패턴
2. LeNet-5
3. AlexNet
4. VGGNet
5. 인셉션과 GoogLeNet
6. ResNet
</br></br></br>

## 5-1. CNN의 디자인 패턴
디자인 패턴이란, 딥러닝 모델 설계 시 사용하는 패턴 구조를 말함.   
</br>

#### 패턴1. 특징 추출과 분류
합성곱 신경망은 크게 특징 추출을 하는 부분과 분류를 맡는 부분으로 나뉨.   
특징 추출 부분은 일련의 합성곱층, 분류 부분은 전결합층으로 구성되며, 거의 모든 합성곱 신경망이 이 구조를 따름.    
</br><img src=""></img></br>

#### 패턴2. 이미지 깊이 증가, 크기는 감소
모든 층은 높이, 폭, 깊이(색상 채널이라고도 함)를 가진 3차원의 이미지를 입력으로 받음. 이후 계층에서 깊이는 색상 채널 대신 이전 층에서 추출된 특징을 나타내는 특징맵이 됨.       
이전 층에서 생성된 새로운 이미지에 합성곱 연산이 적용되고, 합성곱층을 지날 때 마다 이미지의 깊이는 증가하고 크기는 감소하는 경향이 있음.    
</br><img src=""></img></br>

#### 패턴3. 전결합층
대부분 모든 전결합층은 유닛수가 같거나, 이어지는 유닛 수가 감소하는 패턴을 보임(증가하는 경우는 거의 없음).   
이어지는 모든 전결합층의 유닛을 같게 했다고 신경망의 학습 능력이 낮아지는 건 아님.   
</br></br></br>

## 5-2. LeNet-5
가중치를 가진 5개의 층(합성곱층 3개, 전결합층 2개)로 구성된 직관적인 구조.    
LeNet으로 MNIST 데이터셋을 학습시 99%이상의 높은 정확도가 나옴.    
</br>
#### 구조(C는 합성곱층, S는 풀링층, FC는 전결합층)
입력 이미지 → **C1** → TANH → S2 → **C3** → TANH → S4 → **C5** → TANH → **FC6** → **SOFTMAX**
</br><img src=""></img></br>
LeNet-5이 나올 당시 ReLU 함수가 없을 때여서(1998년) tanh함수가 사용됨.   
